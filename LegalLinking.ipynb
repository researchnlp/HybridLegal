{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VChW7ivA1AQx"
      },
      "source": [
        "# AllenNLP Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZUSuM6m1FTb",
        "outputId": "9efc75cb-2fb4-4917-e245-c8cb21ecfc9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-cloud-datastore in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-datastore) (1.31.6)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-datastore) (1.0.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (1.56.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (57.4.0)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (3.17.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (1.15.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (2022.1)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (1.35.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (1.47.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-cloud-datastore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhCW3EbH1ISU",
        "outputId": "82a3caee-3c3a-46b4-d876-dd2d501d9233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TbAUSbO31K0W",
        "outputId": "3d3c8f2c-5ca7-4ccf-c0ea-307a9b1c6042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting allennlp==0.8.1\n",
            "  Downloading allennlp-0.8.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 2.6 MB/s \n",
            "\u001b[?25hCollecting flask-cors==3.0.7\n",
            "  Downloading Flask_Cors-3.0.7-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.1) (1.12.0+cu113)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.1) (4.64.0)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting sqlparse==0.2.4\n",
            "  Downloading sqlparse-0.2.4-py2.py3-none-any.whl (38 kB)\n",
            "Collecting cffi==1.11.5\n",
            "  Downloading cffi-1.11.5-cp37-cp37m-manylinux1_x86_64.whl (421 kB)\n",
            "\u001b[K     |████████████████████████████████| 421 kB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.1) (0.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.1) (1.0.2)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 64.8 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.24.46-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting responses>=0.7\n",
            "  Downloading responses-0.21.0-py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting gevent==1.3.6\n",
            "  Downloading gevent-1.3.6-cp37-cp37m-manylinux1_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 38.1 MB/s \n",
            "\u001b[?25hCollecting flaky\n",
            "  Downloading flaky-3.7.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.1) (3.6.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.1) (1.7.3)\n",
            "Collecting matplotlib==2.2.3\n",
            "  Downloading matplotlib-2.2.3-cp37-cp37m-manylinux1_x86_64.whl (12.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.6 MB 11.9 MB/s \n",
            "\u001b[?25hCollecting moto==1.3.4\n",
            "  Downloading moto-1.3.4-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.1) (3.7)\n",
            "Collecting pytz==2017.3\n",
            "  Downloading pytz-2017.3-py2.py3-none-any.whl (511 kB)\n",
            "\u001b[K     |████████████████████████████████| 511 kB 66.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.1) (1.21.6)\n",
            "Collecting flask==1.0.2\n",
            "  Downloading Flask-1.0.2-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting pytorch-pretrained-bert==0.3.0\n",
            "  Downloading pytorch_pretrained_bert-0.3.0-py3-none-any.whl (37 kB)\n",
            "Collecting awscli>=1.11.91\n",
            "  Downloading awscli-1.25.46-py3-none-any.whl (3.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 48.3 MB/s \n",
            "\u001b[?25hCollecting spacy<2.1,>=2.0\n",
            "  Downloading spacy-2.0.18-cp37-cp37m-manylinux1_x86_64.whl (25.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting numpydoc==0.8.0\n",
            "  Downloading numpydoc-0.8.0.tar.gz (20 kB)\n",
            "Collecting msgpack<0.6.0,>=0.5.6\n",
            "  Downloading msgpack-0.5.6.tar.gz (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 65.8 MB/s \n",
            "\u001b[?25hCollecting tensorboardX==1.2\n",
            "  Downloading tensorboardX-1.2-py2.py3-none-any.whl (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting parsimonious==0.8.0\n",
            "  Downloading parsimonious-0.8.0.tar.gz (38 kB)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.1) (2.23.0)\n",
            "Collecting conllu==0.11\n",
            "  Downloading conllu-0.11-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.1) (3.1.0)\n",
            "Collecting jsonnet==0.10.0\n",
            "  Downloading jsonnet-0.10.0.tar.gz (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 65.4 MB/s \n",
            "\u001b[?25hCollecting overrides\n",
            "  Downloading overrides-6.2.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi==1.11.5->allennlp==0.8.1) (2.21)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.7/dist-packages (from flask==1.0.2->allennlp==0.8.1) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from flask==1.0.2->allennlp==0.8.1) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask==1.0.2->allennlp==0.8.1) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask==1.0.2->allennlp==0.8.1) (7.1.2)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors==3.0.7->allennlp==0.8.1) (1.15.0)\n",
            "Requirement already satisfied: greenlet>=0.4.14 in /usr/local/lib/python3.7/dist-packages (from gevent==1.3.6->allennlp==0.8.1) (1.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.3->allennlp==0.8.1) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.3->allennlp==0.8.1) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.3->allennlp==0.8.1) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.3->allennlp==0.8.1) (3.0.9)\n",
            "Collecting boto>=2.36.0\n",
            "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 64.2 MB/s \n",
            "\u001b[?25hCollecting pyaml\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting python-jose<3.0.0\n",
            "  Downloading python_jose-2.0.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting cookies\n",
            "  Downloading cookies-2.2.1-py2.py3-none-any.whl (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting jsondiff==1.1.1\n",
            "  Downloading jsondiff-1.1.1.tar.gz (7.8 kB)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting cryptography>=2.0.0\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 46.9 MB/s \n",
            "\u001b[?25hCollecting botocore>=1.9.16\n",
            "  Downloading botocore-1.27.46-py3-none-any.whl (9.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0 MB 39.8 MB/s \n",
            "\u001b[?25hCollecting docker>=2.5.1\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 73.1 MB/s \n",
            "\u001b[?25hCollecting aws-xray-sdk<0.96,>=0.93\n",
            "  Downloading aws_xray_sdk-0.95-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sphinx>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from numpydoc==0.8.0->allennlp==0.8.1) (1.8.6)\n",
            "Requirement already satisfied: protobuf>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.2->allennlp==0.8.1) (3.17.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from aws-xray-sdk<0.96,>=0.93->moto==1.3.4->allennlp==0.8.1) (1.14.1)\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting colorama<0.4.5,>=0.2.5\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting rsa<4.8,>=3.1.2\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: PyYAML<5.5,>=3.10 in /usr/local/lib/python3.7/dist-packages (from awscli>=1.11.91->allennlp==0.8.1) (3.13)\n",
            "Collecting docutils<0.17,>=0.10\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 55.3 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting cryptography>=2.0.0\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 38.7 MB/s \n",
            "\u001b[?25h  Downloading cryptography-37.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 38.6 MB/s \n",
            "\u001b[?25h  Downloading cryptography-37.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 36.9 MB/s \n",
            "\u001b[?25h  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 39.1 MB/s \n",
            "\u001b[?25h  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 46.6 MB/s \n",
            "\u001b[?25h  Downloading cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 30.0 MB/s \n",
            "\u001b[?25h  Downloading cryptography-35.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 42.4 MB/s \n",
            "\u001b[?25h  Downloading cryptography-3.4.8-cp36-abi3-manylinux_2_24_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 39.8 MB/s \n",
            "\u001b[?25h  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 32.3 MB/s \n",
            "\u001b[?25h  Downloading cryptography-3.4.6-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 37.1 MB/s \n",
            "\u001b[?25h  Downloading cryptography-3.4.5-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 38.0 MB/s \n",
            "\u001b[?25h  Downloading cryptography-3.4.4-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 34.4 MB/s \n",
            "\u001b[?25h  Downloading cryptography-3.4.3-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 34.0 MB/s \n",
            "\u001b[?25h  Downloading cryptography-3.4.2-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 36.7 MB/s \n",
            "\u001b[?25h  Downloading cryptography-3.4.1-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 29.9 MB/s \n",
            "\u001b[?25h  Downloading cryptography-3.4-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 33.4 MB/s \n",
            "\u001b[?25h  Downloading cryptography-3.3.2-cp36-abi3-manylinux2010_x86_64.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 40.4 MB/s \n",
            "\u001b[?25h  Downloading cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 46.9 MB/s \n",
            "\u001b[?25h  Downloading cryptography-3.3-cp36-abi3-manylinux2010_x86_64.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 47.5 MB/s \n",
            "\u001b[?25h  Downloading cryptography-3.2.1-cp35-abi3-manylinux2010_x86_64.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 43.8 MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10->flask==1.0.2->allennlp==0.8.1) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==2.2.3->allennlp==0.8.1) (4.1.1)\n",
            "Collecting pycryptodome<4.0.0,>=3.3.1\n",
            "  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 46.4 MB/s \n",
            "\u001b[?25hCollecting ecdsa<1.0\n",
            "  Downloading ecdsa-0.18.0-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 11.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future<1.0 in /usr/local/lib/python3.7/dist-packages (from python-jose<3.0.0->moto==1.3.4->allennlp==0.8.1) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==0.8.1) (2.10)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 70.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==0.8.1) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==0.8.1) (3.0.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<4.8,>=3.1.2->awscli>=1.11.91->allennlp==0.8.1) (0.4.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.1,>=2.0->allennlp==0.8.1) (2.0.6)\n",
            "Collecting thinc<6.13.0,>=6.12.1\n",
            "  Downloading thinc-6.12.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 45.5 MB/s \n",
            "\u001b[?25hCollecting preshed<2.1.0,>=2.0.1\n",
            "  Downloading preshed-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 424 kB/s \n",
            "\u001b[?25hCollecting regex==2018.01.10\n",
            "  Downloading regex-2018.01.10.tar.gz (612 kB)\n",
            "\u001b[K     |████████████████████████████████| 612 kB 54.9 MB/s \n",
            "\u001b[?25hCollecting plac<1.0.0,>=0.9.6\n",
            "  Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
            "Collecting dill<0.3,>=0.2\n",
            "  Downloading dill-0.2.9.tar.gz (150 kB)\n",
            "\u001b[K     |████████████████████████████████| 150 kB 54.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.1,>=2.0->allennlp==0.8.1) (1.0.7)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.7/dist-packages (from spacy<2.1,>=2.0->allennlp==0.8.1) (5.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp==0.8.1) (57.4.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp==0.8.1) (0.7.12)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp==0.8.1) (1.2.4)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp==0.8.1) (1.4.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp==0.8.1) (2.2.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp==0.8.1) (2.10.3)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp==0.8.1) (2.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp==0.8.1) (21.3)\n",
            "Collecting cytoolz<0.10,>=0.9.0\n",
            "  Downloading cytoolz-0.9.0.1.tar.gz (443 kB)\n",
            "\u001b[K     |████████████████████████████████| 443 kB 64.3 MB/s \n",
            "\u001b[?25hCollecting msgpack-numpy<0.4.4\n",
            "  Downloading msgpack_numpy-0.4.3.2-py2.py3-none-any.whl (5.2 kB)\n",
            "Collecting wrapt\n",
            "  Downloading wrapt-1.10.11.tar.gz (27 kB)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy<2.1,>=2.0->allennlp==0.8.1) (0.12.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp==0.8.1) (0.2.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp==0.8.1) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonpickle->aws-xray-sdk<0.96,>=0.93->moto==1.3.4->allennlp==0.8.1) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonpickle->aws-xray-sdk<0.96,>=0.93->moto==1.3.4->allennlp==0.8.1) (3.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->allennlp==0.8.1) (1.1.0)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 37.6 MB/s \n",
            "\u001b[?25h  Downloading nltk-3.6.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 49.6 MB/s \n",
            "\u001b[?25h  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 42.9 MB/s \n",
            "\u001b[?25h  Downloading nltk-3.6.3-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.8.1) (1.11.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.8.1) (22.1.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.8.1) (1.4.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.8.1) (8.13.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.8.1) (0.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp==0.8.1) (3.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.2.3->numpydoc==0.8.0->allennlp==0.8.1) (1.1.5)\n",
            "Building wheels for collected packages: jsonnet, jsondiff, numpydoc, parsimonious, msgpack, regex, dill, cytoolz, wrapt\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.10.0-cp37-cp37m-linux_x86_64.whl size=2890883 sha256=c54c87337e1cca6ff6f8ea8104ce384521f0bb74ed5476eefd981645ce04a7e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/27/cf/95fb17431a146150208e0772d2cc0704f8cc6cbfcafc1729a0\n",
            "  Building wheel for jsondiff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsondiff: filename=jsondiff-1.1.1-py3-none-any.whl size=6484 sha256=b5ca24e086db33c94782391329b3bcb398189d6b93ef7be34cf4e255ae498768\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/fe/a7/7ec5152beb08c7fbfd73709aac18861dc97ba4d851056844f2\n",
            "  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numpydoc: filename=numpydoc-0.8.0-py3-none-any.whl size=23066 sha256=fe237043783387b471627a0e80049c6297382042aac530b3b71bb07c26d0b072\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/23/55/179a740eaf5b758a01ec6646a8a6a9ab2153fb40b2a0ba9c83\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.0-py3-none-any.whl size=42642 sha256=f951401c8fa2d66c36bc7a9e0aa8a660b98f634110eac533307c81704835f6fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/69/c1/bc4e991e9ba88ddce03bc38ff1e4926884e09cc703992f4237\n",
            "  Building wheel for msgpack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for msgpack: filename=msgpack-0.5.6-cp37-cp37m-linux_x86_64.whl size=298962 sha256=cb68fe9c84d31151feff6bcc9107bbeb58e141fc2a0eb651e1d032d0c1bfff9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/92/5b/708850ed8872c249ce8ace306b542e1099428491e6b613297b\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2018.1.10-cp37-cp37m-linux_x86_64.whl size=549205 sha256=eee67eedc01c4355ed4054fd01e38abb00daed60ec3e3d3c6590a6c04ac2d987\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/ec/25/0c2b801e792098f7dad5b76157b01be8d0719525c365773e7c\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.2.9-py3-none-any.whl size=77420 sha256=933dca77e0ad6092c456b028c7862a05b3f232543aa12c21355062da9bb8bae7\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/87/19/1fb8f037d75fdc0841c772ecdfd5fdf22f85300d25c73f66cb\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.9.0.1-cp37-cp37m-linux_x86_64.whl size=1239660 sha256=7d10a769feac2fc0ed241de6cfaec837419d352f559acd3735c6d0ed5084fa58\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/9f/8e/8d8bc15ed2c88ed4e784c603f641df40d19e8410b982766e4f\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.10.11-cp37-cp37m-linux_x86_64.whl size=66071 sha256=e3be1709fccbf7687aab458e09c13d6385790d2d0475a76cbd7389a7610be784\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/73/c0/df8f4b8bdfc554d2ba0823c8f80d566cabf702c858e2a49d7b\n",
            "Successfully built jsonnet jsondiff numpydoc parsimonious msgpack regex dill cytoolz wrapt\n",
            "Installing collected packages: urllib3, jmespath, pytz, msgpack, botocore, wrapt, websocket-client, s3transfer, pycryptodome, preshed, plac, msgpack-numpy, jsonpickle, ecdsa, docutils, dill, cytoolz, cffi, xmltodict, thinc, rsa, responses, regex, python-jose, pyaml, mock, jsondiff, flask, docker, cryptography, cookies, colorama, boto3, boto, aws-xray-sdk, unidecode, tensorboardX, sqlparse, spacy, pytorch-pretrained-bert, parsimonious, overrides, numpydoc, nltk, moto, matplotlib, jsonnet, gevent, ftfy, flask-cors, flaky, conllu, awscli, allennlp\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2022.1\n",
            "    Uninstalling pytz-2022.1:\n",
            "      Successfully uninstalled pytz-2022.1\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.4\n",
            "    Uninstalling msgpack-1.0.4:\n",
            "      Successfully uninstalled msgpack-1.0.4\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: preshed\n",
            "    Found existing installation: preshed 3.0.6\n",
            "    Uninstalling preshed-3.0.6:\n",
            "      Successfully uninstalled preshed-3.0.6\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: cffi\n",
            "    Found existing installation: cffi 1.15.1\n",
            "    Uninstalling cffi-1.15.1:\n",
            "      Successfully uninstalled cffi-1.15.1\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.0\n",
            "    Uninstalling thinc-8.1.0:\n",
            "      Successfully uninstalled thinc-8.1.0\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2022.6.2\n",
            "    Uninstalling regex-2022.6.2:\n",
            "      Successfully uninstalled regex-2022.6.2\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 1.1.4\n",
            "    Uninstalling Flask-1.1.4:\n",
            "      Successfully uninstalled Flask-1.1.4\n",
            "  Attempting uninstall: sqlparse\n",
            "    Found existing installation: sqlparse 0.4.2\n",
            "    Uninstalling sqlparse-0.4.2:\n",
            "      Successfully uninstalled sqlparse-0.4.2\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.1\n",
            "    Uninstalling spacy-3.4.1:\n",
            "      Successfully uninstalled spacy-3.4.1\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires wrapt>=1.11.0, but you have wrapt 1.10.11 which is incompatible.\n",
            "plotnine 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 2.2.3 which is incompatible.\n",
            "mizani 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 2.2.3 which is incompatible.\n",
            "en-core-web-sm 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.0.18 which is incompatible.\n",
            "datascience 0.17.5 requires matplotlib>=3.0.0, but you have matplotlib 2.2.3 which is incompatible.\n",
            "arviz 0.12.1 requires matplotlib>=3.0, but you have matplotlib 2.2.3 which is incompatible.\u001b[0m\n",
            "Successfully installed allennlp-0.8.1 aws-xray-sdk-0.95 awscli-1.25.46 boto-2.49.0 boto3-1.24.46 botocore-1.27.46 cffi-1.11.5 colorama-0.4.4 conllu-0.11 cookies-2.2.1 cryptography-3.2.1 cytoolz-0.9.0.1 dill-0.2.9 docker-5.0.3 docutils-0.16 ecdsa-0.18.0 flaky-3.7.0 flask-1.0.2 flask-cors-3.0.7 ftfy-6.1.1 gevent-1.3.6 jmespath-1.0.1 jsondiff-1.1.1 jsonnet-0.10.0 jsonpickle-2.2.0 matplotlib-2.2.3 mock-4.0.3 moto-1.3.4 msgpack-0.5.6 msgpack-numpy-0.4.3.2 nltk-3.6.3 numpydoc-0.8.0 overrides-6.2.0 parsimonious-0.8.0 plac-0.9.6 preshed-2.0.1 pyaml-21.10.1 pycryptodome-3.15.0 python-jose-2.0.2 pytorch-pretrained-bert-0.3.0 pytz-2017.3 regex-2018.1.10 responses-0.21.0 rsa-4.7.2 s3transfer-0.6.0 spacy-2.0.18 sqlparse-0.2.4 tensorboardX-1.2 thinc-6.12.1 unidecode-1.3.4 urllib3-1.25.11 websocket-client-1.3.3 wrapt-1.10.11 xmltodict-0.13.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cffi",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install allennlp==0.8.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9abERyP1v8_",
        "outputId": "8148cab7-5df7-4553-c02f-6c5db1a96858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting overrides==3.1.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Building wheels for collected packages: overrides\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=0b0b0f7af2124a555775f8a85ad7df4f79cba0c6fa945315d7a9a4dba9ad6a1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "Successfully built overrides\n",
            "Installing collected packages: overrides\n",
            "  Attempting uninstall: overrides\n",
            "    Found existing installation: overrides 6.2.0\n",
            "    Uninstalling overrides-6.2.0:\n",
            "      Successfully uninstalled overrides-6.2.0\n",
            "Successfully installed overrides-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install overrides==3.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjBBccdP15no",
        "outputId": "3593a588-592d-4906-967e-3359b7c0906b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn==0.22.2\n",
            "  Downloading scikit_learn-0.22.2-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2) (1.1.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.22.2\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn==0.22.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_FJ7znK18aR",
        "outputId": "dd8a5a60-7e2c-49f4-a913-a15199837f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en_core_web_sm==2.0.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.4 MB 1.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.0.0-py3-none-any.whl size=37405981 sha256=b7c4f9215e40d15169270a3f0b98d931415abfb3fbead586fa079ca3f4a9b3fb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mx7frrtq/wheels/51/df/77/250d8a622c7fc066a42ea4238279337e4a5e04c2602c448ea5\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 3.4.0\n",
            "    Uninstalling en-core-web-sm-3.4.0:\n",
            "      Successfully uninstalled en-core-web-sm-3.4.0\n",
            "Successfully installed en-core-web-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga6P2F5v2Io9"
      },
      "source": [
        "# Running the Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY3P87oX2MaH",
        "outputId": "fdc74722-1ac0-435e-c292-0f5d82ae1821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1Lt5kF5Xs5S1KHOdKGEcZMAPVCDlEo93_/legal-linking-master\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/legal-linking-master'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSCfpa1m2Opu",
        "outputId": "4808ad32-a8e5-4786-e144-0a16dfd91e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1Lt5kF5Xs5S1KHOdKGEcZMAPVCDlEo93_/legal-linking-master\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "2022-08-06 07:52:34,854 - INFO - allennlp.common.params - random_seed = 13370\n",
            "2022-08-06 07:52:34,854 - INFO - allennlp.common.params - numpy_seed = 1337\n",
            "2022-08-06 07:52:34,854 - INFO - allennlp.common.params - pytorch_seed = 133\n",
            "2022-08-06 07:52:34,855 - INFO - allennlp.common.checks - Pytorch version: 1.12.0+cu113\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/run.py\", line 18, in <module>\n",
            "    main(prog=\"allennlp\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/__init__.py\", line 72, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/train.py\", line 111, in train_model_from_args\n",
            "    args.force)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/train.py\", line 144, in train_model_from_file\n",
            "    return train_model(params, serialization_dir, file_friendly_logging, recover, force)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/train.py\", line 281, in train_model\n",
            "    create_serialization_dir(params, serialization_dir, recover, force)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/train.py\", line 208, in create_serialization_dir\n",
            "    raise ConfigurationError(f\"Serialization directory ({serialization_dir}) already exists and is \"\n",
            "allennlp.common.checks.ConfigurationError: 'Serialization directory (tmp2) already exists and is not empty. Specify --recover to recover training from existing output.'\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/legal-linking-master'\n",
        "!allennlp train legal.json -s tmp2 --include-package mylib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuyP7kzP2Wyv",
        "outputId": "edd754a7-f7ea-4f4a-959b-5154343cd202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1Lt5kF5Xs5S1KHOdKGEcZMAPVCDlEo93_/legal-linking-master/tmp/vocabulary\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/legal-linking-master/tmp/vocabulary'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IezBJtZM2XLs"
      },
      "outputs": [],
      "source": [
        "!cp bert.txt .bert.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTKA4c8n2XSR",
        "outputId": "3b053ebd-2fa6-446a-9ef5-b0921e759a04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1Lt5kF5Xs5S1KHOdKGEcZMAPVCDlEo93_/legal-linking-master/tmp\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/legal-linking-master/tmp'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw4Sd9GD2Xna",
        "outputId": "bb26ba07-05a6-4a14-9035-8f55d9bb6427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weights.th\n",
            "tar: weights.th: file changed as we read it\n",
            "vocabulary/\n",
            "vocabulary/non_padded_namespaces.txt\n",
            "vocabulary/labels.txt\n",
            "vocabulary/.bert.txt\n",
            "vocabulary/.ipynb_checkpoints/\n",
            "config.json\n"
          ]
        }
      ],
      "source": [
        "!cp best.th weights.th\n",
        "!tar -cvzf model.tar.gz weights.th vocabulary/ config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwYbdst92kVS"
      },
      "source": [
        "# Preparing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwmZDIXn2oSw"
      },
      "outputs": [],
      "source": [
        "%cd '/content/drive/MyDrive/legal-linking-master/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRBPvZrH3Tcs"
      },
      "outputs": [],
      "source": [
        "!bash /content/drive/MyDrive/legal-linking-master/data/mkdata.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJe8J1vT3bRx"
      },
      "source": [
        "# Linear Model Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdoiu5Yy3TsY",
        "outputId": "c436fd97-96b9-4481-d71f-0be07e43eaa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1Lt5kF5Xs5S1KHOdKGEcZMAPVCDlEo93_/legal-linking-master\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/legal-linking-master'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA-r3eAZ3T9X"
      },
      "outputs": [],
      "source": [
        "!python linear_model.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwSvxcJA3k62"
      },
      "source": [
        "# Neural Network Model Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSL2Jk1lXwfS",
        "outputId": "4f0fb1f5-3149-49ee-e09e-362af4c7eda3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1Lt5kF5Xs5S1KHOdKGEcZMAPVCDlEo93_/legal-linking-master\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/legal-linking-master'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00NXYbm1gyCy",
        "outputId": "96f232bb-f11d-4051-ec45-c2b019ca5221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "2022-06-26 05:46:52,597 - INFO - allennlp.models.archival - loading archive file /content/drive/MyDrive/legal-linking-master/tmp/model.tar.gz\n",
            "2022-06-26 05:46:52,597 - INFO - allennlp.models.archival - extracting archive file /content/drive/MyDrive/legal-linking-master/tmp/model.tar.gz to temp dir /tmp/tmp0xw5lak2\n",
            "2022-06-26 05:46:56,793 - INFO - allennlp.common.params - type = default\n",
            "2022-06-26 05:46:56,793 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmp0xw5lak2/vocabulary.\n",
            "2022-06-26 05:46:56,794 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'const_path': 'data', 'doc_encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 300, 'input_size': 768, 'num_layers': 2, 'type': 'lstm'}, 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'tokens': ['tokens', 'tokens-offsets']}, 'token_embedders': {'tokens': {'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained'}}}, 'tokens_namespace': 'tokens', 'type': 'legal_classifier', 'use_classifier': False, 'use_sim': True} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 05:46:56,794 - INFO - allennlp.common.params - model.type = legal_classifier\n",
            "2022-06-26 05:46:56,794 - INFO - allennlp.common.from_params - instantiating class <class 'mylib.legal_model.LegalClassifier'> from params {'const_path': 'data', 'doc_encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 300, 'input_size': 768, 'num_layers': 2, 'type': 'lstm'}, 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'tokens': ['tokens', 'tokens-offsets']}, 'token_embedders': {'tokens': {'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained'}}}, 'tokens_namespace': 'tokens', 'use_classifier': False, 'use_sim': True} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 05:46:56,795 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'tokens': ['tokens', 'tokens-offsets']}, 'token_embedders': {'tokens': {'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained'}}} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 05:46:56,795 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
            "2022-06-26 05:46:56,795 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = True\n",
            "2022-06-26 05:46:56,795 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained'} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 05:46:56,795 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = bert-pretrained\n",
            "2022-06-26 05:46:56,795 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertEmbedder'> from params {'pretrained_model': 'bert-base-cased'} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 05:46:56,795 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.pretrained_model = bert-base-cased\n",
            "2022-06-26 05:46:56,795 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.requires_grad = False\n",
            "2022-06-26 05:46:56,795 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.top_layer_only = False\n",
            "2022-06-26 05:46:57,086 - INFO - pytorch_pretrained_bert.modeling - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz from cache at /root/.pytorch_pretrained_bert/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c\n",
            "2022-06-26 05:46:57,086 - INFO - pytorch_pretrained_bert.modeling - extracting archive file /root/.pytorch_pretrained_bert/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c to temp dir /tmp/tmpxp9kw_cu\n",
            "2022-06-26 05:47:00,730 - INFO - pytorch_pretrained_bert.modeling - Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "2022-06-26 05:47:02,499 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 300, 'input_size': 768, 'num_layers': 2, 'type': 'lstm'} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 05:47:02,500 - INFO - allennlp.common.params - model.doc_encoder.type = lstm\n",
            "2022-06-26 05:47:02,500 - INFO - allennlp.common.params - model.doc_encoder.batch_first = True\n",
            "2022-06-26 05:47:02,500 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2022-06-26 05:47:02,500 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2022-06-26 05:47:02,500 - INFO - allennlp.common.params - model.doc_encoder.bidirectional = True\n",
            "2022-06-26 05:47:02,500 - INFO - allennlp.common.params - model.doc_encoder.dropout = 0.5\n",
            "2022-06-26 05:47:02,500 - INFO - allennlp.common.params - model.doc_encoder.hidden_size = 300\n",
            "2022-06-26 05:47:02,500 - INFO - allennlp.common.params - model.doc_encoder.input_size = 768\n",
            "2022-06-26 05:47:02,500 - INFO - allennlp.common.params - model.doc_encoder.num_layers = 2\n",
            "2022-06-26 05:47:02,500 - INFO - allennlp.common.params - model.doc_encoder.batch_first = True\n",
            "2022-06-26 05:47:02,535 - INFO - allennlp.common.params - model.const_path = data\n",
            "2022-06-26 05:47:02,535 - INFO - allennlp.common.params - model.tokens_namespace = tokens\n",
            "2022-06-26 05:47:02,535 - INFO - allennlp.common.params - model.use_sim = True\n",
            "2022-06-26 05:47:02,535 - INFO - allennlp.common.params - model.use_classifier = False\n",
            "2022-06-26 05:47:03,116 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
            "{'unmatched': 0, 'amendmentxiv': 1, 'first_amendment': 2, 'fourth_amendment': 3, 'fifth_amendment': 4, 'articlei#section8': 5, 'eighth_amendment': 6, 'sixth_amendment': 7, 'seventh_amendment': 8, 'amendmentxi': 9, 'articleiv#section2': 10, 'amendmentxv': 11, 'second_amendment': 12, 'tenth_amendment': 13, 'articleiv#section1': 14, 'articleii#section2': 15, 'amendmentxiii': 16, 'amendmentxxi': 17, 'articlei#section10': 18, 'signers': 19, 'amendmentxvii': 20, 'articleii#section1': 21, 'amendmentxvi': 22, 'articlei#section3': 23, 'amendmentxviii': 24, 'amendmentxix': 25, 'amendmentxxv': 26, 'amendmentxx': 27, 'ninth_amendment': 28, 'articlei#section9': 29, 'articlei#section2': 30, 'articlei#section7': 31, 'amendmentxxiv': 32, 'amendmentxii': 33, 'amendmentxxvi': 34, 'amendmentxxii': 35, 'articlei#section6': 36, 'articlevi': 37, 'articleiii#section3': 38, 'articleiii#section2': 39, 'articlei#section5': 40, 'articleiv#section3': 41, 'third_amendment': 42, 'articleiii#section1': 43, 'amendmentxxiii': 44, 'articlei#section4': 45, 'articlevii': 46, 'preamble': 47, 'articleii#section4': 48, 'articleiv#section4': 49, 'amendmentxxvii': 50, 'articlei#section1': 51, 'articlev': 52, 'articleii#section3': 53}\n",
            "dict_keys(['articleii#section2', 'amendmentxxi', 'second_amendment', 'articleiv#section4', 'articlei#section1', 'articleii#section3', 'articlev', 'third_amendment', 'articleiii#section2', 'articlei#section4', 'amendmentxiv', 'articleii#section4', 'preamble', 'amendmentxi', 'signers', 'tenth_amendment', 'articlei#section2', 'articleiv#section1', 'amendmentxxiii', 'articlei#section5', 'amendmentxvi', 'articleii#section1', 'sixth_amendment', 'amendmentxx', 'amendmentxii', 'articlei#section7', 'amendmentxviii', 'articleiii#section3', 'articleiv#section2', 'articlei#section8', 'articleiii#section1', 'eighth_amendment', 'amendmentxvii', 'fifth_amendment', 'articleiv#section3', 'amendmentxxvii', 'amendmentxxii', 'articlevi', 'amendmentxxvi', 'amendmentxxiv', 'amendmentxxv', 'amendmentxix', 'articlei#section10', 'amendmentxiii', 'ninth_amendment', 'articlei#section3', 'first_amendment', 'articlevii', 'articlei#section9', 'articlei#section6', 'fourth_amendment', 'seventh_amendment', 'amendmentxv'])\n",
            "Embedding the constitution... this could take a minute...\n",
            "Done embedding the constitution.\n",
            "2022-06-26 05:47:51,639 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'token_indexers': {'tokens': {'do_lowercase': False, 'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained', 'use_starting_offsets': True}}, 'type': 'legal_reader'} and extras {}\n",
            "2022-06-26 05:47:51,639 - INFO - allennlp.common.params - dataset_reader.type = legal_reader\n",
            "2022-06-26 05:47:51,639 - INFO - allennlp.common.from_params - instantiating class <class 'mylib.legal_reader.LegalDatasetReader'> from params {'token_indexers': {'tokens': {'do_lowercase': False, 'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained', 'use_starting_offsets': True}}} and extras {}\n",
            "2022-06-26 05:47:51,639 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained', 'use_starting_offsets': True} and extras {}\n",
            "2022-06-26 05:47:51,639 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = bert-pretrained\n",
            "2022-06-26 05:47:51,640 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'bert-base-cased', 'use_starting_offsets': True} and extras {}\n",
            "2022-06-26 05:47:51,640 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.pretrained_model = bert-base-cased\n",
            "2022-06-26 05:47:51,640 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.use_starting_offsets = True\n",
            "2022-06-26 05:47:51,640 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.do_lowercase = False\n",
            "2022-06-26 05:47:51,640 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.never_lowercase = None\n",
            "2022-06-26 05:47:51,640 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_pieces = 512\n",
            "2022-06-26 05:47:51,953 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
            "2022-06-26 05:47:51,978 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "731it [00:00, 2708.22it/s]{'pos': 395, 'neg': 753}\n",
            "1148it [00:00, 3596.17it/s]\n",
            "2022-06-26 05:47:56,108 - WARNING - allennlp.data.token_indexers.wordpiece_indexer - Too many wordpieces, truncating: ['Had', 'the', 'doctor', 'defendant', 'here', ',', 'or', 'even', 'the', 'nondoctor', 'defendant', ',', 'been', 'convicted', 'for', 'doing', 'nothing', 'more', 'than', 'expressing', 'opinions', 'to', 'persons', 'coming', 'to', 'the', 'clinic', 'that', 'certain', 'contraceptive', 'devices', ',', 'medicines', 'or', 'practices', 'would', 'do', 'them', 'good', 'and', 'would', 'be', 'desirable', ',', 'or', 'for', 'telling', 'people', 'how', 'devices', 'could', 'be', 'used', ',', 'I', 'can', 'think', 'of', 'no', 'reasons', 'at', 'this', 'time', 'why', 'their', 'expressions', 'of', 'views', 'would', 'not', 'be', '[', 'p508', ']', 'protected', 'by', 'the', 'First', 'and', 'Fourteenth', 'Amendments', ',', 'which', 'guarantee', 'freedom', 'of', 'speech', '.', 'Cf', '.', 'Brotherhood', 'of', 'Railroad', 'Trainmen', 'v.', 'Virginia', 'ex', 'rel', '.', 'Virginia', 'State', 'Bar', ',', '377', 'U.S.', '1', ';', 'NAACP', 'v.', 'Button', ',', '371', 'U.S.', '415', '.', 'But', 'speech', 'is', 'one', 'thing', ';', 'conduct', 'and', 'physical', 'activities', 'are', 'quite', 'another', '.', 'See', ',', 'e.g.', ',', 'Cox', 'v.', 'Louisiana', ',', '379', 'U.S.', '536', ',', '554', '-', '555', ';', 'Cox', 'v.', 'Louisiana', ',', '379', 'U.S.', '559', ',', '563', '-', '564', ';', 'i', 'd', '.', '575', '-', '584', '(', 'concurring', 'opinion', ')', ';', 'Giboney', 'v.', 'Empire', 'Storage', '&', 'Ice', 'Co.', ',', '336', 'U.S.', '490', ';', 'cf', '.', 'Reynolds', 'v.', 'United', 'States', ',', '98', 'U.S.', '145', ',', '163', '-', '164', '.', 'The', 'two', 'defendants', 'here', 'were', 'active', 'participants', 'in', 'an', 'organization', 'which', 'gave', 'physical', 'examinations', 'to', 'women', ',', 'advised', 'them', 'what', 'kind', 'of', 'contraceptive', 'devices', 'or', 'medicines', 'would', 'most', 'likely', 'be', 'satisfactory', 'for', 'them', ',', 'and', 'then', 'supplied', 'the', 'devices', 'themselves', ',', 'all', 'for', 'a', 'graduated', 'scale', 'of', 'fees', ',', 'based', 'on', 'the', 'family', 'income', '.', 'Thus', ',', 'these', 'defendants', 'admittedly', 'engaged', 'with', 'others', 'in', 'a', 'planned', 'course', 'of', 'conduct', 'to', 'help', 'people', 'violate', 'the', 'Connecticut', 'law', '.', 'Merely', 'because', 'some', 'speech', 'was', 'used', 'in', 'carrying', 'on', 'that', 'conduct', '--', 'just', 'as', ',', 'in', 'ordinary', 'life', ',', 'some', 'speech', 'accompanies', 'most', 'kinds', 'of', 'conduct', '--', 'we', 'are', 'not', ',', 'in', 'my', 'view', ',', 'justified', 'in', 'holding', 'that', 'the', 'First', 'Amendment', 'forbids', 'the', 'State', 'to', 'punish', 'their', 'conduct', '.', 'Strongly', 'as', 'I', 'desire', 'to', 'protect', 'all', 'First', 'Amendment', 'freedoms', ',', 'I', 'am', 'unable', 'to', 'stretch', 'the', 'Amendment', 'so', 'as', 'to', 'afford', 'protection', 'to', 'the', 'conduct', 'of', 'these', 'defendants', 'in', 'violating', 'the', 'Connecticut', 'law', '.', 'What', 'would', 'be', 'the', 'constitutional', 'fate', 'of', 'the', 'law', 'if', 'hereafter', 'applied', 'to', 'punish', 'nothing', 'but', 'speech', 'is', ',', 'as', 'I', 'have', 'said', ',', 'quite', 'another', 'matter', '.', 'The', 'Court', 'talks', 'about', 'a', 'constitutional', '\"', 'right', 'of', 'privacy', '\"', 'as', 'though', 'there', 'is', 'some', 'constitutional', 'provision', 'or', 'provisions', 'forbidding', 'any', 'law', 'ever', 'to', 'be', 'passed', 'which', 'might', 'abridge', 'the', '\"', 'privacy', '\"', 'of', 'individuals', '.', 'But', 'there', 'is', 'not', '.', 'There', 'are', ',', 'of', 'course', ',', 'guarantees', 'in', 'certain', 'specific', 'constitutional', 'provisions', 'which', 'are', 'designed', 'in', 'part', 'to', 'protect', 'privacy', 'at', 'certain', 'times', 'and', 'places', 'with', 'respect', 'to', 'certain', 'activities', '.', 'Such', ',', 'for', 'example', ',', 'is', 'the', 'Fourth', '[', 'p509', ']', 'Amendment', \"'s\", 'guarantee', 'against', '\"', 'unreasonable', 'searches', 'and', 'seizures', '.', '\"', 'But', 'I', 'think', 'it', 'belittles', 'that', 'Amendment', 'to', 'talk', 'about', 'it', 'as', 'though', 'it', 'protects', 'nothing', 'but', '\"', 'privacy', '.', '\"', 'To', 'treat', 'it', 'that', 'way', 'is', 'to', 'give', 'it', 'a', 'niggardly', 'interpretation', ',', 'not', 'the', 'kind', 'of', 'liberal', 'reading', 'I', 'think', 'any', 'Bill', 'of', 'Rights', 'provision', 'should', 'be', 'given', '.', 'The', 'average', 'man', 'would', 'very', 'likely', 'not', 'have', 'his', 'feelings', 'soothed', 'any', 'more', 'by', 'having', 'his', 'property', 'seized', 'openly', 'than', 'by', 'having', 'it', 'seized', 'privately', 'and', 'by', 'stealth', '.', 'He', 'simply', 'wants', 'his', 'property', 'left', 'alone', '.', 'And', 'a', 'person', 'can', 'be', 'just', 'as', 'much', ',', 'if', 'not', 'more', ',', 'irritated', ',', 'annoyed', 'and', 'injured', 'by', 'an', 'unceremonious', 'public', 'arrest', 'by', 'a', 'policeman', 'as', 'he', 'is', 'by', 'a', 'seizure', 'in', 'the', 'privacy', 'of', 'his', 'office', 'or', 'home', '.']\n",
            "2022-06-26 05:47:56,331 - WARNING - allennlp.data.token_indexers.wordpiece_indexer - Too many wordpieces, truncating: ['The', 'due', 'process', 'argument', 'which', 'my', 'Brothers', 'HARLAN', 'and', 'WHITE', 'adopt', 'here', 'is', 'based', ',', 'as', 'their', 'opinions', 'indicate', ',', 'on', 'the', 'premise', 'that', 'this', 'Court', 'is', 'vested', 'with', 'power', 'to', 'invalidate', 'all', 'state', 'laws', 'that', 'it', 'considers', 'to', 'be', 'arbitrary', ',', 'capricious', ',', 'unreasonable', ',', 'or', 'oppressive', ',', 'or', 'on', 'this', 'Court', \"'s\", 'belief', 'that', 'a', 'particular', 'state', 'law', 'under', 'scrutiny', 'has', 'no', '\"', 'rational', 'or', 'justifying', '\"', 'purpose', ',', 'or', 'is', 'offensive', 'to', 'a', '\"', 'sense', 'of', 'fairness', 'and', 'justice', '.', '\"', '[', 'n3', ']', 'If', 'these', 'formulas', 'based', 'on', '\"', 'natural', 'justice', ',', '\"', 'or', 'others', 'which', 'mean', 'the', 'same', 'thing', ',', '[', 'n4', ']', 'are', 'to', 'prevail', ',', 'they', 'require', 'judges', 'to', 'determine', '[', 'p512', ']', 'what', 'is', 'or', 'is', 'not', 'constitutional', 'on', 'the', 'basis', 'of', 'their', 'own', 'appraisal', 'of', 'what', 'laws', 'are', 'unwise', 'or', 'unnecessary', '.', 'The', 'power', 'to', 'make', 'such', 'decisions', 'is', ',', 'of', 'course', ',', 'that', 'of', 'a', 'legislative', 'body', '.', 'Surely', 'it', 'has', 'to', 'be', 'admitted', 'that', 'no', 'provision', 'of', 'the', 'Constitution', 'specifically', 'gives', 'such', 'blanket', 'power', 'to', 'courts', 'to', 'exercise', 'such', 'a', 'supervisory', 'veto', 'over', 'the', 'wisdom', 'and', 'value', 'of', 'legislative', 'policies', 'and', 'to', 'hold', 'unconstitutional', 'those', 'laws', 'which', 'they', 'believe', 'unwise', 'or', 'dangerous', '.', 'I', 'readily', 'admit', 'that', 'no', 'legislative', 'body', ',', 'state', 'or', 'national', ',', 'should', 'pass', 'laws', 'that', 'can', 'justly', 'be', 'given', 'any', '[', 'p513', ']', 'of', 'the', 'invidious', 'labels', 'invoked', 'as', 'constitutional', 'excuses', 'to', 'strike', 'down', 'state', 'laws', '.', 'But', 'perhaps', 'it', 'is', 'not', 'too', 'much', 'to', 'say', 'that', 'no', 'legislative', 'body', 'ever', 'does', 'pass', 'laws', 'without', 'believing', 'that', 'they', 'will', 'accomplish', 'a', 'sane', ',', 'rational', ',', 'wise', 'and', 'justifiable', 'purpose', '.', 'While', 'I', 'completely', 'subscribe', 'to', 'the', 'holding', 'of', 'Marbury', 'v.', 'Madison', ',', '1', 'Cranch', '137', ',', 'and', 'subsequent', 'cases', ',', 'that', 'our', 'Court', 'has', 'constitutional', 'power', 'to', 'strike', 'down', 'statutes', ',', 'state', 'or', 'federal', ',', 'that', 'violate', 'commands', 'of', 'the', 'Federal', 'Constitution', ',', 'I', 'do', 'not', 'believe', 'that', 'we', 'are', 'granted', 'power', 'by', 'the', 'Due', 'Process', 'Clause', 'or', 'any', 'other', 'constitutional', 'provision', 'or', 'provisions', 'to', 'measure', 'constitutionality', 'by', 'our', 'belief', 'that', 'legislation', 'is', 'arbitrary', ',', 'capricious', 'or', 'unreasonable', ',', 'or', 'accomplishes', 'no', 'justifiable', 'purpose', ',', 'or', 'is', 'offensive', 'to', 'our', 'own', 'notions', 'of', '\"', 'civilized', 'standards', 'of', 'conduct', '.', '\"', '[', 'n5', ']', 'Such', 'an', 'appraisal', 'of', 'the', 'wisdom', 'of', 'legislation', 'is', 'an', 'attribute', 'of', 'the', 'power', 'to', 'make', 'laws', ',', 'not', 'of', 'the', 'power', 'to', 'interpret', 'them', '.', 'The', 'use', 'by', 'federal', 'courts', 'of', 'such', 'a', 'formula', 'or', 'doctrine', 'or', 'whatnot', 'to', 'veto', 'federal', 'or', 'state', 'laws', 'simply', 'takes', 'away', 'from', 'Congress', 'and', 'States', 'the', 'power', 'to', 'make', 'laws', 'based', 'on', 'their', 'own', 'judgment', 'of', 'fairness', 'and', 'wisdom', ',', 'and', 'transfers', 'that', 'power', 'to', 'this', 'Court', 'for', 'ultimate', 'determination', '--', 'a', 'power', 'which', 'was', 'specifically', 'denied', 'to', 'federal', 'courts', 'by', 'the', 'convention', 'that', 'framed', 'the', 'Constitution', '.', '[', 'n6', ']', '[', 'p514', ']']\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/run.py\", line 18, in <module>\n",
            "    main(prog=\"allennlp\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/__init__.py\", line 72, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/predict.py\", line 200, in _predict\n",
            "    manager.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/predict.py\", line 176, in run\n",
            "    for model_input_instance, result in zip(batch, self._predict_instances(batch)):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/predict.py\", line 137, in _predict_instances\n",
            "    results = [self._predictor.predict_instance(batch_data[0])]\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1Lt5kF5Xs5S1KHOdKGEcZMAPVCDlEo93_/legal-linking-master/mylib/legal_predictor.py\", line 24, in predict_instance\n",
            "    result = super().predict_instance(instance)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/predictors/predictor.py\", line 58, in predict_instance\n",
            "    outputs = self._model.forward_on_instance(instance)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/models/model.py\", line 124, in forward_on_instance\n",
            "    return self.forward_on_instances([instance])[0]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/models/model.py\", line 155, in forward_on_instances\n",
            "    outputs = self.decode(self(**model_input))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1Lt5kF5Xs5S1KHOdKGEcZMAPVCDlEo93_/legal-linking-master/mylib/legal_model.py\", line 132, in forward\n",
            "    const_doc_emb = self._doc_encoder(self.const_emb, self.const_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py\", line 73, in forward\n",
            "    self.sort_and_run_forward(self._module, inputs, mask, hidden_state)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/modules/encoder_base.py\", line 92, in sort_and_run_forward\n",
            "    num_valid = torch.sum(mask[:, 0]).int().item()\n",
            "RuntimeError: CUDA error: an illegal memory access was encountered\n",
            "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
            "2022-06-26 05:47:56,452 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmp0xw5lak2\n"
          ]
        }
      ],
      "source": [
        "!allennlp predict \"/content/drive/MyDrive/legal-linking-master/tmp/model.tar.gz\" data/validation/all_validation --include-package mylib --cuda-device 0 --use-dataset-reader --output legalbert.txt --predictor legal_predictor --silent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4vtrWU4XvQg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCL30n1Z3s0-"
      },
      "source": [
        "# Score Result Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD1zFaEf3UWC",
        "outputId": "3a540e9f-9985-4d80-ac8a-5bb61d0da0a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "{'pos': 395, 'neg': 753}\n",
            "{'pos': 308, 'neg': 840}\n",
            "06/26/2022 06:11:12 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
            "100% 2296/2296 [00:00<00:00, 17257.08it/s]\n",
            "P: 0.7653631284914063\n",
            "R: 0.5479999999998905\n",
            "F1: 0.6386946386458594\n"
          ]
        }
      ],
      "source": [
        "!python score.py --gold data/validation/all_validation --pred results/legalbert.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlQ7Znvl3yBd",
        "outputId": "60ad8dac-753b-498b-9680-5e0218455519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "{'pos': 395, 'neg': 753}\n",
            "{'pos': 345, 'neg': 803}\n",
            "06/26/2022 05:54:14 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
            "100% 2296/2296 [00:00<00:00, 16710.20it/s]\n",
            "P: 0.683417085426964\n",
            "R: 0.5439999999998912\n",
            "F1: 0.6057906458302429\n"
          ]
        }
      ],
      "source": [
        "!python score.py --gold data/validation/all_validation --pred results/linear-remove.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5t3CAU83yGi",
        "outputId": "543488fa-9d9e-4ded-ea19-0528c3796064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "{'pos': 395, 'neg': 753}\n",
            "{'pos': 227, 'neg': 921}\n",
            "06/26/2022 06:26:05 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
            "100% 2296/2296 [00:00<00:00, 17300.64it/s]\n",
            "P: 0.8210526315786593\n",
            "R: 0.46799999999990644\n",
            "F1: 0.5961783439026433\n"
          ]
        }
      ],
      "source": [
        "!python score.py --gold data/validation/all_validation --pred results/bert.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLLbLb3U3yNG",
        "outputId": "79cfef78-3948-4b62-bcd5-55216aea3594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "{'pos': 395, 'neg': 753}\n",
            "{'pos': 312, 'neg': 836}\n",
            "06/26/2022 06:26:10 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
            "100% 2296/2296 [00:00<00:00, 16703.85it/s]\n",
            "P: 0.7656675749316715\n",
            "R: 0.5619999999998876\n",
            "F1: 0.6482122260179244\n"
          ]
        }
      ],
      "source": [
        "!python score.py --gold data/validation/all_validation --pred results/bert-remove.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M7-Mzp-3yTq",
        "outputId": "c7619f05-7a06-44f0-ba24-56108f4901c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "{'pos': 395, 'neg': 753}\n",
            "{'pos': 221, 'neg': 927}\n",
            "06/26/2022 06:26:15 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
            "100% 2296/2296 [00:00<00:00, 16935.63it/s]\n",
            "P: 0.9179687499996415\n",
            "R: 0.469999999999906\n",
            "F1: 0.6216931216481657\n"
          ]
        }
      ],
      "source": [
        "!python score.py --gold data/validation/all_validation --pred results/rules.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avEdRQSc3yZa"
      },
      "outputs": [],
      "source": [
        "!python combine.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpVqisqm3ye9",
        "outputId": "09932d32-b75e-4fa5-92e9-475a523a5520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "{'pos': 395, 'neg': 753}\n",
            "{'pos': 331, 'neg': 817}\n",
            "08/03/2022 13:01:51 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
            "100% 2296/2296 [00:00<00:00, 17570.52it/s]\n",
            "P: 0.866847826086721\n",
            "R: 0.6379999999998724\n",
            "F1: 0.7350230414256413\n"
          ]
        }
      ],
      "source": [
        "!python score.py --gold data/validation/all_validation.txt --pred results/rules-gru.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efqdc0Ck3_Pk",
        "outputId": "2f6c025a-1a19-49a4-d7bd-6db0b630255c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "{'pos': 395, 'neg': 753}\n",
            "{'pos': 347, 'neg': 801}\n",
            "06/26/2022 06:28:59 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
            "100% 2296/2296 [00:00<00:00, 17448.18it/s]\n",
            "P: 0.6954436450837661\n",
            "R: 0.579999999999884\n",
            "F1: 0.6324972736689195\n"
          ]
        }
      ],
      "source": [
        "!python score.py --gold data/validation/all_validation --pred results/rules-linear.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkbRJslz3_Uj",
        "outputId": "7f768b05-8154-42d9-a245-aec7c7c3474e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "{'pos': 395, 'neg': 753}\n",
            "{'pos': 398, 'neg': 750}\n",
            "06/26/2022 06:29:03 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
            "100% 2296/2296 [00:00<00:00, 17013.24it/s]\n",
            "P: 0.6382113821136914\n",
            "R: 0.6279999999998744\n",
            "F1: 0.6330645160789079\n"
          ]
        }
      ],
      "source": [
        "!python score.py --gold data/validation/all_validation --pred results/bert-linear.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN7fQsxH3_bI",
        "outputId": "d70cf801-3deb-40ab-ba32-1ca6643b1e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "{'pos': 395, 'neg': 753}\n",
            "{'pos': 398, 'neg': 750}\n",
            "06/26/2022 06:29:08 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
            "100% 2296/2296 [00:00<00:00, 17068.69it/s]\n",
            "P: 0.6441351888666712\n",
            "R: 0.6479999999998705\n",
            "F1: 0.6460618145062027\n"
          ]
        }
      ],
      "source": [
        "!python score.py --gold data/validation/all_validation --pred results/bert-linear-rules.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b_CTzMR3_ik",
        "outputId": "a86c4011-fa8a-4f90-b5dc-0ed95bff4ed5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "{'pos': 395, 'neg': 753}\n",
            "{'pos': 312, 'neg': 836}\n",
            "06/26/2022 06:28:50 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
            "100% 2296/2296 [00:00<00:00, 16905.78it/s]\n",
            "P: 0.8338108882519101\n",
            "R: 0.5819999999998836\n",
            "F1: 0.6855123674425863\n"
          ]
        }
      ],
      "source": [
        "!python score.py --gold data/validation/all_validation --pred results/rules-bert2.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I366pYEzSaPo",
        "outputId": "992b7e7d-5899-4555-ba95-b33a835e8574"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "2022-06-26 14:48:11,902 - INFO - allennlp.common.params - random_seed = 13370\n",
            "2022-06-26 14:48:11,903 - INFO - allennlp.common.params - numpy_seed = 1337\n",
            "2022-06-26 14:48:11,903 - INFO - allennlp.common.params - pytorch_seed = 133\n",
            "2022-06-26 14:48:11,903 - INFO - allennlp.common.checks - Pytorch version: 1.11.0+cu113\n",
            "2022-06-26 14:48:11,914 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'token_indexers': {'tokens': {'do_lowercase': False, 'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained', 'use_starting_offsets': True}}, 'type': 'legal_reader'} and extras {}\n",
            "2022-06-26 14:48:11,914 - INFO - allennlp.common.params - dataset_reader.type = legal_reader\n",
            "2022-06-26 14:48:11,915 - INFO - allennlp.common.from_params - instantiating class <class 'mylib.legal_reader.LegalDatasetReader'> from params {'token_indexers': {'tokens': {'do_lowercase': False, 'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained', 'use_starting_offsets': True}}} and extras {}\n",
            "2022-06-26 14:48:11,915 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained', 'use_starting_offsets': True} and extras {}\n",
            "2022-06-26 14:48:11,915 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = bert-pretrained\n",
            "2022-06-26 14:48:11,915 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'bert-base-cased', 'use_starting_offsets': True} and extras {}\n",
            "2022-06-26 14:48:11,916 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.pretrained_model = bert-base-cased\n",
            "2022-06-26 14:48:11,916 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.use_starting_offsets = True\n",
            "2022-06-26 14:48:11,916 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.do_lowercase = False\n",
            "2022-06-26 14:48:11,916 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.never_lowercase = None\n",
            "2022-06-26 14:48:11,916 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_pieces = 512\n",
            "2022-06-26 14:48:12,672 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
            "2022-06-26 14:48:12,699 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2022-06-26 14:48:12,700 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
            "2022-06-26 14:48:12,700 - INFO - allennlp.common.params - train_data_path = /content/drive/MyDrive/legal-linking-master/data/all.train\n",
            "2022-06-26 14:48:12,700 - INFO - allennlp.commands.train - Reading training data from /content/drive/MyDrive/legal-linking-master/data/all.train\n",
            "39002it [00:07, 8127.89it/s]{'pos': 17062, 'neg': 22326}\n",
            "39388it [00:07, 5469.05it/s]\n",
            "2022-06-26 14:48:19,904 - INFO - allennlp.common.params - validation_data_path = /content/drive/MyDrive/legal-linking-master/data/all.test\n",
            "2022-06-26 14:48:19,904 - INFO - allennlp.commands.train - Reading validation data from /content/drive/MyDrive/legal-linking-master/data/all.test\n",
            "9685it [00:01, 8478.94it/s]{'pos': 4386, 'neg': 5576}\n",
            "9962it [00:01, 5691.04it/s]\n",
            "2022-06-26 14:48:21,655 - INFO - allennlp.common.params - test_data_path = None\n",
            "2022-06-26 14:48:21,656 - INFO - allennlp.commands.train - From dataset instances, train, validation will be considered for vocabulary creation.\n",
            "2022-06-26 14:48:21,656 - INFO - allennlp.common.params - vocabulary.type = None\n",
            "2022-06-26 14:48:21,656 - INFO - allennlp.common.params - vocabulary.extend = False\n",
            "2022-06-26 14:48:21,656 - INFO - allennlp.common.params - vocabulary.directory_path = None\n",
            "2022-06-26 14:48:21,656 - INFO - allennlp.common.params - vocabulary.min_count = None\n",
            "2022-06-26 14:48:21,657 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n",
            "2022-06-26 14:48:21,657 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n",
            "2022-06-26 14:48:21,657 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n",
            "2022-06-26 14:48:21,657 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n",
            "2022-06-26 14:48:21,657 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n",
            "2022-06-26 14:48:21,657 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
            "49350it [00:00, 77196.76it/s]\n",
            "2022-06-26 14:48:22,298 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'const_path': 'data', 'doc_encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 300, 'input_size': 768, 'num_layers': 2, 'type': 'gru'}, 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'tokens': ['tokens', 'tokens-offsets']}, 'token_embedders': {'tokens': {'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained'}}}, 'tokens_namespace': 'tokens', 'type': 'legal_classifier', 'use_classifier': False, 'use_sim': True} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 14:48:22,298 - INFO - allennlp.common.params - model.type = legal_classifier\n",
            "2022-06-26 14:48:22,298 - INFO - allennlp.common.from_params - instantiating class <class 'mylib.legal_model.LegalClassifier'> from params {'const_path': 'data', 'doc_encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 300, 'input_size': 768, 'num_layers': 2, 'type': 'gru'}, 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'tokens': ['tokens', 'tokens-offsets']}, 'token_embedders': {'tokens': {'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained'}}}, 'tokens_namespace': 'tokens', 'use_classifier': False, 'use_sim': True} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 14:48:22,299 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'tokens': ['tokens', 'tokens-offsets']}, 'token_embedders': {'tokens': {'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained'}}} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 14:48:22,299 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
            "2022-06-26 14:48:22,299 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = True\n",
            "2022-06-26 14:48:22,299 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained'} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 14:48:22,300 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = bert-pretrained\n",
            "2022-06-26 14:48:22,300 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertEmbedder'> from params {'pretrained_model': 'bert-base-cased'} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 14:48:22,300 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.pretrained_model = bert-base-cased\n",
            "2022-06-26 14:48:22,300 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.requires_grad = False\n",
            "2022-06-26 14:48:22,300 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.top_layer_only = False\n",
            "2022-06-26 14:48:23,099 - INFO - pytorch_pretrained_bert.modeling - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz from cache at /root/.pytorch_pretrained_bert/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c\n",
            "2022-06-26 14:48:23,100 - INFO - pytorch_pretrained_bert.modeling - extracting archive file /root/.pytorch_pretrained_bert/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c to temp dir /tmp/tmpu25pkamb\n",
            "2022-06-26 14:48:26,729 - INFO - pytorch_pretrained_bert.modeling - Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "2022-06-26 14:48:28,536 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 300, 'input_size': 768, 'num_layers': 2, 'type': 'gru'} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 14:48:28,536 - INFO - allennlp.common.params - model.doc_encoder.type = gru\n",
            "2022-06-26 14:48:28,537 - INFO - allennlp.common.params - model.doc_encoder.batch_first = True\n",
            "2022-06-26 14:48:28,537 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2022-06-26 14:48:28,537 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2022-06-26 14:48:28,537 - INFO - allennlp.common.params - model.doc_encoder.bidirectional = True\n",
            "2022-06-26 14:48:28,538 - INFO - allennlp.common.params - model.doc_encoder.dropout = 0.5\n",
            "2022-06-26 14:48:28,538 - INFO - allennlp.common.params - model.doc_encoder.hidden_size = 300\n",
            "2022-06-26 14:48:28,538 - INFO - allennlp.common.params - model.doc_encoder.input_size = 768\n",
            "2022-06-26 14:48:28,538 - INFO - allennlp.common.params - model.doc_encoder.num_layers = 2\n",
            "2022-06-26 14:48:28,538 - INFO - allennlp.common.params - model.doc_encoder.batch_first = True\n",
            "2022-06-26 14:48:28,565 - INFO - allennlp.common.params - model.const_path = data\n",
            "2022-06-26 14:48:28,565 - INFO - allennlp.common.params - model.tokens_namespace = tokens\n",
            "2022-06-26 14:48:28,565 - INFO - allennlp.common.params - model.use_sim = True\n",
            "2022-06-26 14:48:28,565 - INFO - allennlp.common.params - model.use_classifier = False\n",
            "2022-06-26 14:48:29,613 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
            "{'unmatched': 0, 'amendmentxiv': 1, 'first_amendment': 2, 'fourth_amendment': 3, 'fifth_amendment': 4, 'articlei#section8': 5, 'eighth_amendment': 6, 'sixth_amendment': 7, 'seventh_amendment': 8, 'amendmentxi': 9, 'articleiv#section2': 10, 'amendmentxv': 11, 'second_amendment': 12, 'tenth_amendment': 13, 'articleiv#section1': 14, 'articleii#section2': 15, 'amendmentxiii': 16, 'amendmentxxi': 17, 'articlei#section10': 18, 'signers': 19, 'amendmentxvii': 20, 'articleii#section1': 21, 'amendmentxvi': 22, 'articlei#section3': 23, 'amendmentxviii': 24, 'amendmentxix': 25, 'amendmentxxv': 26, 'amendmentxx': 27, 'ninth_amendment': 28, 'articlei#section9': 29, 'articlei#section2': 30, 'articlei#section7': 31, 'amendmentxxiv': 32, 'amendmentxii': 33, 'amendmentxxvi': 34, 'amendmentxxii': 35, 'articlei#section6': 36, 'articlevi': 37, 'articleiii#section3': 38, 'articleiii#section2': 39, 'articlei#section5': 40, 'articleiv#section3': 41, 'third_amendment': 42, 'articleiii#section1': 43, 'amendmentxxiii': 44, 'articlei#section4': 45, 'articlevii': 46, 'preamble': 47, 'articleii#section4': 48, 'articleiv#section4': 49, 'amendmentxxvii': 50, 'articlei#section1': 51, 'articlev': 52, 'articleii#section3': 53}\n",
            "dict_keys(['articleii#section2', 'amendmentxxi', 'second_amendment', 'articleiv#section4', 'articlei#section1', 'articleii#section3', 'articlev', 'third_amendment', 'articleiii#section2', 'articlei#section4', 'amendmentxiv', 'articleii#section4', 'preamble', 'amendmentxi', 'signers', 'tenth_amendment', 'articlei#section2', 'articleiv#section1', 'amendmentxxiii', 'articlei#section5', 'amendmentxvi', 'articleii#section1', 'sixth_amendment', 'amendmentxx', 'amendmentxii', 'articlei#section7', 'amendmentxviii', 'articleiii#section3', 'articleiv#section2', 'articlei#section8', 'articleiii#section1', 'eighth_amendment', 'amendmentxvii', 'fifth_amendment', 'articleiv#section3', 'amendmentxxvii', 'amendmentxxii', 'articlevi', 'amendmentxxvi', 'amendmentxxiv', 'amendmentxxv', 'amendmentxix', 'articlei#section10', 'amendmentxiii', 'ninth_amendment', 'articlei#section3', 'first_amendment', 'articlevii', 'articlei#section9', 'articlei#section6', 'fourth_amendment', 'seventh_amendment', 'amendmentxv'])\n",
            "Embedding the constitution... this could take a minute...\n",
            "Done embedding the constitution.\n",
            "2022-06-26 14:49:19,660 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 2, 'type': 'basic'} and extras {}\n",
            "2022-06-26 14:49:19,661 - INFO - allennlp.common.params - iterator.type = basic\n",
            "2022-06-26 14:49:19,661 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 2} and extras {}\n",
            "2022-06-26 14:49:19,661 - INFO - allennlp.common.params - iterator.batch_size = 2\n",
            "2022-06-26 14:49:19,661 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n",
            "2022-06-26 14:49:19,661 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n",
            "2022-06-26 14:49:19,662 - INFO - allennlp.common.params - iterator.cache_instances = False\n",
            "2022-06-26 14:49:19,662 - INFO - allennlp.common.params - iterator.track_epoch = False\n",
            "2022-06-26 14:49:19,662 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n",
            "2022-06-26 14:49:19,662 - INFO - allennlp.common.params - validation_iterator = None\n",
            "2022-06-26 14:49:19,662 - INFO - allennlp.common.params - trainer.no_grad = ()\n",
            "2022-06-26 14:49:19,664 - INFO - allennlp.commands.train - Following parameters are Frozen  (without gradient):\n",
            "2022-06-26 14:49:19,664 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.embeddings.word_embeddings.weight\n",
            "2022-06-26 14:49:19,664 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.embeddings.position_embeddings.weight\n",
            "2022-06-26 14:49:19,664 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.embeddings.token_type_embeddings.weight\n",
            "2022-06-26 14:49:19,664 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.embeddings.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,665 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.embeddings.LayerNorm.beta\n",
            "2022-06-26 14:49:19,665 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-06-26 14:49:19,665 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-06-26 14:49:19,665 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-06-26 14:49:19,665 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-06-26 14:49:19,665 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-06-26 14:49:19,665 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-06-26 14:49:19,665 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-06-26 14:49:19,666 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-06-26 14:49:19,666 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.attention.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,666 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.attention.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,666 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-06-26 14:49:19,666 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-06-26 14:49:19,666 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.output.dense.weight\n",
            "2022-06-26 14:49:19,666 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.output.dense.bias\n",
            "2022-06-26 14:49:19,666 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,667 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.0.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,667 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-06-26 14:49:19,667 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-06-26 14:49:19,667 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-06-26 14:49:19,667 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-06-26 14:49:19,667 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-06-26 14:49:19,667 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-06-26 14:49:19,667 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-06-26 14:49:19,667 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-06-26 14:49:19,668 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.attention.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,668 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.attention.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,668 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-06-26 14:49:19,668 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-06-26 14:49:19,668 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.output.dense.weight\n",
            "2022-06-26 14:49:19,668 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.output.dense.bias\n",
            "2022-06-26 14:49:19,668 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,668 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.1.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,669 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-06-26 14:49:19,669 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-06-26 14:49:19,669 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-06-26 14:49:19,669 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-06-26 14:49:19,669 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-06-26 14:49:19,669 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-06-26 14:49:19,669 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-06-26 14:49:19,669 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-06-26 14:49:19,670 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.attention.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,670 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.attention.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,670 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-06-26 14:49:19,670 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-06-26 14:49:19,670 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.output.dense.weight\n",
            "2022-06-26 14:49:19,670 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.output.dense.bias\n",
            "2022-06-26 14:49:19,670 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,670 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.2.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,670 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-06-26 14:49:19,671 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-06-26 14:49:19,671 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-06-26 14:49:19,671 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-06-26 14:49:19,671 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-06-26 14:49:19,671 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-06-26 14:49:19,671 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-06-26 14:49:19,671 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-06-26 14:49:19,672 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.attention.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,672 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.attention.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,672 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-06-26 14:49:19,672 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-06-26 14:49:19,672 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.output.dense.weight\n",
            "2022-06-26 14:49:19,672 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.output.dense.bias\n",
            "2022-06-26 14:49:19,672 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,673 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.3.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,673 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-06-26 14:49:19,673 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-06-26 14:49:19,673 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-06-26 14:49:19,673 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-06-26 14:49:19,673 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-06-26 14:49:19,673 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-06-26 14:49:19,674 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-06-26 14:49:19,674 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-06-26 14:49:19,674 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.attention.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,674 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.attention.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,674 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-06-26 14:49:19,674 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-06-26 14:49:19,674 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.output.dense.weight\n",
            "2022-06-26 14:49:19,674 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.output.dense.bias\n",
            "2022-06-26 14:49:19,675 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,675 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.4.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,675 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-06-26 14:49:19,675 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-06-26 14:49:19,675 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-06-26 14:49:19,675 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-06-26 14:49:19,675 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-06-26 14:49:19,675 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-06-26 14:49:19,676 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-06-26 14:49:19,676 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-06-26 14:49:19,676 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.attention.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,676 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.attention.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,676 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-06-26 14:49:19,676 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-06-26 14:49:19,676 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.output.dense.weight\n",
            "2022-06-26 14:49:19,676 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.output.dense.bias\n",
            "2022-06-26 14:49:19,677 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,677 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.5.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,677 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-06-26 14:49:19,677 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-06-26 14:49:19,677 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-06-26 14:49:19,677 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-06-26 14:49:19,677 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-06-26 14:49:19,677 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-06-26 14:49:19,678 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-06-26 14:49:19,678 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-06-26 14:49:19,678 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.attention.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,678 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.attention.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,678 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-06-26 14:49:19,738 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-06-26 14:49:19,738 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.output.dense.weight\n",
            "2022-06-26 14:49:19,738 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.output.dense.bias\n",
            "2022-06-26 14:49:19,738 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,738 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.6.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,738 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-06-26 14:49:19,739 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-06-26 14:49:19,739 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-06-26 14:49:19,739 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-06-26 14:49:19,739 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-06-26 14:49:19,739 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-06-26 14:49:19,739 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-06-26 14:49:19,739 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-06-26 14:49:19,740 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.attention.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,740 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.attention.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,740 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-06-26 14:49:19,740 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-06-26 14:49:19,740 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.output.dense.weight\n",
            "2022-06-26 14:49:19,741 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.output.dense.bias\n",
            "2022-06-26 14:49:19,741 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,741 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.7.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,741 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-06-26 14:49:19,741 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-06-26 14:49:19,741 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-06-26 14:49:19,742 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-06-26 14:49:19,742 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-06-26 14:49:19,742 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-06-26 14:49:19,742 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-06-26 14:49:19,742 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-06-26 14:49:19,742 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.attention.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,743 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.attention.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,743 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-06-26 14:49:19,743 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-06-26 14:49:19,743 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.output.dense.weight\n",
            "2022-06-26 14:49:19,743 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.output.dense.bias\n",
            "2022-06-26 14:49:19,743 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,744 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.8.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,744 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-06-26 14:49:19,744 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-06-26 14:49:19,744 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-06-26 14:49:19,744 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-06-26 14:49:19,744 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-06-26 14:49:19,745 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-06-26 14:49:19,745 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-06-26 14:49:19,745 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-06-26 14:49:19,745 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.attention.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,745 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.attention.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,745 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-06-26 14:49:19,746 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-06-26 14:49:19,746 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.output.dense.weight\n",
            "2022-06-26 14:49:19,746 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.output.dense.bias\n",
            "2022-06-26 14:49:19,746 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,746 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.9.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,746 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-06-26 14:49:19,746 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-06-26 14:49:19,747 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-06-26 14:49:19,747 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-06-26 14:49:19,747 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-06-26 14:49:19,747 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-06-26 14:49:19,747 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-06-26 14:49:19,747 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-06-26 14:49:19,747 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.attention.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,747 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.attention.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,747 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-06-26 14:49:19,748 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-06-26 14:49:19,748 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.output.dense.weight\n",
            "2022-06-26 14:49:19,748 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.output.dense.bias\n",
            "2022-06-26 14:49:19,748 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,748 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.10.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,748 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-06-26 14:49:19,748 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-06-26 14:49:19,748 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-06-26 14:49:19,749 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-06-26 14:49:19,749 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-06-26 14:49:19,749 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-06-26 14:49:19,749 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-06-26 14:49:19,749 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-06-26 14:49:19,749 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.attention.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,749 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.attention.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,749 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-06-26 14:49:19,750 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-06-26 14:49:19,750 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.output.dense.weight\n",
            "2022-06-26 14:49:19,750 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.output.dense.bias\n",
            "2022-06-26 14:49:19,750 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.output.LayerNorm.gamma\n",
            "2022-06-26 14:49:19,750 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.encoder.layer.11.output.LayerNorm.beta\n",
            "2022-06-26 14:49:19,750 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.pooler.dense.weight\n",
            "2022-06-26 14:49:19,750 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens.bert_model.pooler.dense.bias\n",
            "2022-06-26 14:49:19,751 - INFO - allennlp.commands.train - Following parameters are Tunable (with gradient):\n",
            "2022-06-26 14:49:19,751 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens._scalar_mix.gamma\n",
            "2022-06-26 14:49:19,751 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens._scalar_mix.scalar_parameters.0\n",
            "2022-06-26 14:49:19,751 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens._scalar_mix.scalar_parameters.1\n",
            "2022-06-26 14:49:19,751 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens._scalar_mix.scalar_parameters.2\n",
            "2022-06-26 14:49:19,751 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens._scalar_mix.scalar_parameters.3\n",
            "2022-06-26 14:49:19,751 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens._scalar_mix.scalar_parameters.4\n",
            "2022-06-26 14:49:19,752 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens._scalar_mix.scalar_parameters.5\n",
            "2022-06-26 14:49:19,752 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens._scalar_mix.scalar_parameters.6\n",
            "2022-06-26 14:49:19,752 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens._scalar_mix.scalar_parameters.7\n",
            "2022-06-26 14:49:19,752 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens._scalar_mix.scalar_parameters.8\n",
            "2022-06-26 14:49:19,752 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens._scalar_mix.scalar_parameters.9\n",
            "2022-06-26 14:49:19,752 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens._scalar_mix.scalar_parameters.10\n",
            "2022-06-26 14:49:19,752 - INFO - allennlp.commands.train - _token_embedder.token_embedder_tokens._scalar_mix.scalar_parameters.11\n",
            "2022-06-26 14:49:19,753 - INFO - allennlp.commands.train - _doc_encoder._module.weight_ih_l0\n",
            "2022-06-26 14:49:19,753 - INFO - allennlp.commands.train - _doc_encoder._module.weight_hh_l0\n",
            "2022-06-26 14:49:19,753 - INFO - allennlp.commands.train - _doc_encoder._module.bias_ih_l0\n",
            "2022-06-26 14:49:19,753 - INFO - allennlp.commands.train - _doc_encoder._module.bias_hh_l0\n",
            "2022-06-26 14:49:19,753 - INFO - allennlp.commands.train - _doc_encoder._module.weight_ih_l0_reverse\n",
            "2022-06-26 14:49:19,753 - INFO - allennlp.commands.train - _doc_encoder._module.weight_hh_l0_reverse\n",
            "2022-06-26 14:49:19,753 - INFO - allennlp.commands.train - _doc_encoder._module.bias_ih_l0_reverse\n",
            "2022-06-26 14:49:19,753 - INFO - allennlp.commands.train - _doc_encoder._module.bias_hh_l0_reverse\n",
            "2022-06-26 14:49:19,754 - INFO - allennlp.commands.train - _doc_encoder._module.weight_ih_l1\n",
            "2022-06-26 14:49:19,754 - INFO - allennlp.commands.train - _doc_encoder._module.weight_hh_l1\n",
            "2022-06-26 14:49:19,754 - INFO - allennlp.commands.train - _doc_encoder._module.bias_ih_l1\n",
            "2022-06-26 14:49:19,754 - INFO - allennlp.commands.train - _doc_encoder._module.bias_hh_l1\n",
            "2022-06-26 14:49:19,754 - INFO - allennlp.commands.train - _doc_encoder._module.weight_ih_l1_reverse\n",
            "2022-06-26 14:49:19,754 - INFO - allennlp.commands.train - _doc_encoder._module.weight_hh_l1_reverse\n",
            "2022-06-26 14:49:19,754 - INFO - allennlp.commands.train - _doc_encoder._module.bias_ih_l1_reverse\n",
            "2022-06-26 14:49:19,755 - INFO - allennlp.commands.train - _doc_encoder._module.bias_hh_l1_reverse\n",
            "2022-06-26 14:49:19,755 - INFO - allennlp.commands.train - sim_ff._module._linear_layers.0.weight\n",
            "2022-06-26 14:49:19,755 - INFO - allennlp.commands.train - sim_ff._module._linear_layers.0.bias\n",
            "2022-06-26 14:49:19,755 - INFO - allennlp.common.params - trainer.type = default\n",
            "2022-06-26 14:49:19,755 - INFO - allennlp.common.params - trainer.patience = 25\n",
            "2022-06-26 14:49:19,755 - INFO - allennlp.common.params - trainer.validation_metric = +f1\n",
            "2022-06-26 14:49:19,755 - INFO - allennlp.common.params - trainer.shuffle = True\n",
            "2022-06-26 14:49:19,755 - INFO - allennlp.common.params - trainer.num_epochs = 5\n",
            "2022-06-26 14:49:19,756 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
            "2022-06-26 14:49:19,756 - INFO - allennlp.common.params - trainer.grad_norm = 5\n",
            "2022-06-26 14:49:19,756 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
            "2022-06-26 14:49:19,756 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n",
            "2022-06-26 14:49:19,931 - INFO - allennlp.common.params - trainer.optimizer.type = adam\n",
            "2022-06-26 14:49:19,931 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None\n",
            "2022-06-26 14:49:19,932 - INFO - allennlp.training.optimizers - Number of trainable parameters: 3550815\n",
            "2022-06-26 14:49:19,932 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2022-06-26 14:49:19,932 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2022-06-26 14:49:19,932 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001\n",
            "2022-06-26 14:49:19,933 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 3\n",
            "2022-06-26 14:49:19,933 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n",
            "2022-06-26 14:49:19,933 - INFO - allennlp.common.params - trainer.model_save_interval = None\n",
            "2022-06-26 14:49:19,933 - INFO - allennlp.common.params - trainer.summary_interval = 100\n",
            "2022-06-26 14:49:19,934 - INFO - allennlp.common.params - trainer.histogram_interval = None\n",
            "2022-06-26 14:49:19,934 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n",
            "2022-06-26 14:49:19,934 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n",
            "2022-06-26 14:49:19,934 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n",
            "2022-06-26 14:49:19,961 - INFO - allennlp.common.params - evaluate_on_test = False\n",
            "2022-06-26 14:49:19,962 - INFO - allennlp.training.trainer - Beginning training.\n",
            "2022-06-26 14:49:19,962 - INFO - allennlp.training.trainer - Epoch 0/4\n",
            "2022-06-26 14:49:19,963 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5089.572\n",
            "2022-06-26 14:49:20,094 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1461\n",
            "2022-06-26 14:49:20,095 - INFO - allennlp.training.trainer - Training\n",
            "prec: 0.5935, rec: 0.8878, f1: 0.7114, loss: 0.4131 ||: 100%|##########| 19694/19694 [41:36<00:00,  7.89it/s]\n",
            "2022-06-26 15:30:56,915 - INFO - allennlp.training.trainer - Validating\n",
            "prec: 0.8419, rec: 0.9304, f1: 0.8839, loss: 0.2817 ||: 100%|##########| 4981/4981 [03:44<00:00, 22.19it/s]\n",
            "2022-06-26 15:34:41,354 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "2022-06-26 15:34:41,355 - INFO - allennlp.training.trainer - rec             |     0.888  |     0.930\n",
            "2022-06-26 15:34:41,355 - INFO - allennlp.training.trainer - gpu_0_memory_MB |  1461.000  |       N/A\n",
            "2022-06-26 15:34:41,356 - INFO - allennlp.training.trainer - loss            |     0.413  |     0.282\n",
            "2022-06-26 15:34:41,356 - INFO - allennlp.training.trainer - f1              |     0.711  |     0.884\n",
            "2022-06-26 15:34:41,356 - INFO - allennlp.training.trainer - cpu_memory_MB   |  5089.572  |       N/A\n",
            "2022-06-26 15:34:41,357 - INFO - allennlp.training.trainer - prec            |     0.593  |     0.842\n",
            "2022-06-26 15:34:42,956 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to 'tmp1/best.th'.\n",
            "2022-06-26 15:34:45,108 - INFO - allennlp.training.trainer - Epoch duration: 00:45:25\n",
            "2022-06-26 15:34:45,108 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:01:40\n",
            "2022-06-26 15:34:45,108 - INFO - allennlp.training.trainer - Epoch 1/4\n",
            "2022-06-26 15:34:45,108 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5166.772\n",
            "2022-06-26 15:34:45,243 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 2053\n",
            "2022-06-26 15:34:45,245 - INFO - allennlp.training.trainer - Training\n",
            "prec: 0.8293, rec: 0.9255, f1: 0.8748, loss: 0.2742 ||: 100%|##########| 19694/19694 [41:19<00:00,  7.94it/s]\n",
            "2022-06-26 16:16:04,677 - INFO - allennlp.training.trainer - Validating\n",
            "prec: 0.9256, rec: 0.9197, f1: 0.9226, loss: 0.4312 ||: 100%|##########| 4981/4981 [03:41<00:00, 22.50it/s]\n",
            "2022-06-26 16:19:46,032 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "2022-06-26 16:19:46,033 - INFO - allennlp.training.trainer - rec             |     0.926  |     0.920\n",
            "2022-06-26 16:19:46,033 - INFO - allennlp.training.trainer - gpu_0_memory_MB |  2053.000  |       N/A\n",
            "2022-06-26 16:19:46,033 - INFO - allennlp.training.trainer - loss            |     0.274  |     0.431\n",
            "2022-06-26 16:19:46,034 - INFO - allennlp.training.trainer - f1              |     0.875  |     0.923\n",
            "2022-06-26 16:19:46,034 - INFO - allennlp.training.trainer - cpu_memory_MB   |  5166.772  |       N/A\n",
            "2022-06-26 16:19:46,034 - INFO - allennlp.training.trainer - prec            |     0.829  |     0.926\n",
            "2022-06-26 16:19:47,931 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to 'tmp1/best.th'.\n",
            "2022-06-26 16:19:50,513 - INFO - allennlp.training.trainer - Epoch duration: 00:45:05\n",
            "2022-06-26 16:19:50,518 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:15:45\n",
            "2022-06-26 16:19:50,518 - INFO - allennlp.training.trainer - Epoch 2/4\n",
            "2022-06-26 16:19:50,519 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5166.78\n",
            "2022-06-26 16:19:50,706 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 2053\n",
            "2022-06-26 16:19:50,708 - INFO - allennlp.training.trainer - Training\n",
            "prec: 0.8583, rec: 0.9265, f1: 0.8911, loss: 0.2734 ||: 100%|##########| 19694/19694 [41:18<00:00,  7.95it/s]\n",
            "2022-06-26 17:01:09,393 - INFO - allennlp.training.trainer - Validating\n",
            "prec: 0.9168, rec: 0.9239, f1: 0.9204, loss: 0.2816 ||: 100%|##########| 4981/4981 [03:41<00:00, 22.47it/s]\n",
            "2022-06-26 17:04:51,060 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "2022-06-26 17:04:51,061 - INFO - allennlp.training.trainer - rec             |     0.927  |     0.924\n",
            "2022-06-26 17:04:51,061 - INFO - allennlp.training.trainer - gpu_0_memory_MB |  2053.000  |       N/A\n",
            "2022-06-26 17:04:51,062 - INFO - allennlp.training.trainer - loss            |     0.273  |     0.282\n",
            "2022-06-26 17:04:51,062 - INFO - allennlp.training.trainer - f1              |     0.891  |     0.920\n",
            "2022-06-26 17:04:51,062 - INFO - allennlp.training.trainer - cpu_memory_MB   |  5166.780  |       N/A\n",
            "2022-06-26 17:04:51,062 - INFO - allennlp.training.trainer - prec            |     0.858  |     0.917\n",
            "2022-06-26 17:04:52,664 - INFO - allennlp.training.trainer - Epoch duration: 00:45:02\n",
            "2022-06-26 17:04:52,665 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:30:21\n",
            "2022-06-26 17:04:52,665 - INFO - allennlp.training.trainer - Epoch 3/4\n",
            "2022-06-26 17:04:52,665 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5166.78\n",
            "2022-06-26 17:04:52,800 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 2053\n",
            "2022-06-26 17:04:52,801 - INFO - allennlp.training.trainer - Training\n",
            "prec: 0.8689, rec: 0.9250, f1: 0.8960, loss: 0.2834 ||: 100%|##########| 19694/19694 [41:18<00:00,  7.95it/s]\n",
            "2022-06-26 17:46:10,901 - INFO - allennlp.training.trainer - Validating\n",
            "prec: 0.9580, rec: 0.9210, f1: 0.9392, loss: 0.3261 ||: 100%|##########| 4981/4981 [03:42<00:00, 22.41it/s]\n",
            "2022-06-26 17:49:53,212 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "2022-06-26 17:49:53,212 - INFO - allennlp.training.trainer - rec             |     0.925  |     0.921\n",
            "2022-06-26 17:49:53,213 - INFO - allennlp.training.trainer - gpu_0_memory_MB |  2053.000  |       N/A\n",
            "2022-06-26 17:49:53,214 - INFO - allennlp.training.trainer - loss            |     0.283  |     0.326\n",
            "2022-06-26 17:49:53,214 - INFO - allennlp.training.trainer - f1              |     0.896  |     0.939\n",
            "2022-06-26 17:49:53,214 - INFO - allennlp.training.trainer - cpu_memory_MB   |  5166.780  |       N/A\n",
            "2022-06-26 17:49:53,214 - INFO - allennlp.training.trainer - prec            |     0.869  |     0.958\n",
            "2022-06-26 17:49:54,852 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to 'tmp1/best.th'.\n",
            "2022-06-26 17:49:57,099 - INFO - allennlp.training.trainer - Epoch duration: 00:45:04\n",
            "2022-06-26 17:49:57,100 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:45:09\n",
            "2022-06-26 17:49:57,100 - INFO - allennlp.training.trainer - Epoch 4/4\n",
            "2022-06-26 17:49:57,100 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5166.78\n",
            "2022-06-26 17:49:57,253 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 2055\n",
            "2022-06-26 17:49:57,254 - INFO - allennlp.training.trainer - Training\n",
            "prec: 0.8737, rec: 0.9296, f1: 0.9008, loss: 0.2688 ||: 100%|##########| 19694/19694 [41:22<00:00,  7.93it/s]\n",
            "2022-06-26 18:31:19,419 - INFO - allennlp.training.trainer - Validating\n",
            "prec: 0.9459, rec: 0.9252, f1: 0.9354, loss: 0.2791 ||: 100%|##########| 4981/4981 [03:42<00:00, 22.43it/s]\n",
            "2022-06-26 18:35:01,513 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "2022-06-26 18:35:01,514 - INFO - allennlp.training.trainer - rec             |     0.930  |     0.925\n",
            "2022-06-26 18:35:01,514 - INFO - allennlp.training.trainer - gpu_0_memory_MB |  2055.000  |       N/A\n",
            "2022-06-26 18:35:01,515 - INFO - allennlp.training.trainer - loss            |     0.269  |     0.279\n",
            "2022-06-26 18:35:01,515 - INFO - allennlp.training.trainer - f1              |     0.901  |     0.935\n",
            "2022-06-26 18:35:01,515 - INFO - allennlp.training.trainer - cpu_memory_MB   |  5166.780  |       N/A\n",
            "2022-06-26 18:35:01,516 - INFO - allennlp.training.trainer - prec            |     0.874  |     0.946\n",
            "2022-06-26 18:35:03,257 - INFO - allennlp.training.trainer - Epoch duration: 00:45:06\n",
            "2022-06-26 18:35:03,257 - INFO - allennlp.models.archival - archiving weights and vocabulary to tmp1/model.tar.gz\n",
            "2022-06-26 18:35:30,614 - INFO - allennlp.commands.train - Loading the best epoch weights.\n",
            "2022-06-26 18:35:31,330 - INFO - allennlp.common.util - Metrics: {\n",
            "  \"peak_cpu_memory_MB\": 5166.78,\n",
            "  \"peak_gpu_0_memory_MB\": 2055,\n",
            "  \"training_duration\": \"03:45:41\",\n",
            "  \"training_start_epoch\": 0,\n",
            "  \"training_epochs\": 4,\n",
            "  \"epoch\": 4,\n",
            "  \"training_prec\": 0.8737122468465709,\n",
            "  \"training_rec\": 0.9295834892797898,\n",
            "  \"training_f1\": 0.900782342833832,\n",
            "  \"training_loss\": 0.26876043446352077,\n",
            "  \"training_cpu_memory_MB\": 5166.78,\n",
            "  \"training_gpu_0_memory_MB\": 2055,\n",
            "  \"validation_prec\": 0.9459401709401507,\n",
            "  \"validation_rec\": 0.9251828631138782,\n",
            "  \"validation_f1\": 0.9354463813551633,\n",
            "  \"validation_loss\": 0.27911516944052894,\n",
            "  \"best_epoch\": 3,\n",
            "  \"best_validation_prec\": 0.9580434782608487,\n",
            "  \"best_validation_rec\": 0.921003134796219,\n",
            "  \"best_validation_f1\": 0.9391582311700314,\n",
            "  \"best_validation_loss\": 0.3261013198586545\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "!allennlp train legalgru.json -s tmp1 --include-package mylib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O439ITyPtnn0",
        "outputId": "fae34b54-c038-4ee2-8ae6-bb9cd47c9a18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1Lt5kF5Xs5S1KHOdKGEcZMAPVCDlEo93_/legal-linking-master/tmp1/vocabulary\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/legal-linking-master/tmp1/vocabulary'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKsgJZ8vc76O"
      },
      "outputs": [],
      "source": [
        "!cp bert.txt .bert.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bVWfJJ1dMIF",
        "outputId": "0823991d-3b90-4054-b81f-77348620bd45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1Lt5kF5Xs5S1KHOdKGEcZMAPVCDlEo93_/legal-linking-master/tmp1\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/legal-linking-master/tmp1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-8_bHEPc_t0",
        "outputId": "4321a5fa-532e-4afc-fdde-7797905554e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weights.th\n",
            "vocabulary/\n",
            "vocabulary/non_padded_namespaces.txt\n",
            "vocabulary/labels.txt\n",
            "vocabulary/.bert.txt\n",
            "vocabulary/.ipynb_checkpoints/\n",
            "config.json\n"
          ]
        }
      ],
      "source": [
        "!cp best.th weights.th\n",
        "!tar -cvzf model.tar.gz weights.th vocabulary/ config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXZCxEi6dfIS",
        "outputId": "130bc362-10c1-4cfc-ff4a-0f9e98538c61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1Lt5kF5Xs5S1KHOdKGEcZMAPVCDlEo93_/legal-linking-master\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/legal-linking-master'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3LoClPndSdq",
        "outputId": "464ee148-dcbe-4a37-ee34-b9338a9c6436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "2022-06-26 19:31:37,697 - INFO - allennlp.models.archival - loading archive file /content/drive/MyDrive/legal-linking-master/tmp1/model.tar.gz\n",
            "2022-06-26 19:31:37,697 - INFO - allennlp.models.archival - extracting archive file /content/drive/MyDrive/legal-linking-master/tmp1/model.tar.gz to temp dir /tmp/tmp0a4ilwzj\n",
            "2022-06-26 19:31:41,898 - INFO - allennlp.common.params - type = default\n",
            "2022-06-26 19:31:41,899 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmp0a4ilwzj/vocabulary.\n",
            "2022-06-26 19:31:41,899 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'const_path': 'data', 'doc_encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 300, 'input_size': 768, 'num_layers': 2, 'type': 'gru'}, 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'tokens': ['tokens', 'tokens-offsets']}, 'token_embedders': {'tokens': {'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained'}}}, 'tokens_namespace': 'tokens', 'type': 'legal_classifier', 'use_classifier': False, 'use_sim': True} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 19:31:41,899 - INFO - allennlp.common.params - model.type = legal_classifier\n",
            "2022-06-26 19:31:41,899 - INFO - allennlp.common.from_params - instantiating class <class 'mylib.legal_model.LegalClassifier'> from params {'const_path': 'data', 'doc_encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 300, 'input_size': 768, 'num_layers': 2, 'type': 'gru'}, 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'tokens': ['tokens', 'tokens-offsets']}, 'token_embedders': {'tokens': {'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained'}}}, 'tokens_namespace': 'tokens', 'use_classifier': False, 'use_sim': True} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 19:31:41,900 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'tokens': ['tokens', 'tokens-offsets']}, 'token_embedders': {'tokens': {'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained'}}} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 19:31:41,900 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
            "2022-06-26 19:31:41,900 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = True\n",
            "2022-06-26 19:31:41,900 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained'} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 19:31:41,900 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = bert-pretrained\n",
            "2022-06-26 19:31:41,900 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertEmbedder'> from params {'pretrained_model': 'bert-base-cased'} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 19:31:41,900 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.pretrained_model = bert-base-cased\n",
            "2022-06-26 19:31:41,900 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.requires_grad = False\n",
            "2022-06-26 19:31:41,900 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.top_layer_only = False\n",
            "2022-06-26 19:31:42,656 - INFO - pytorch_pretrained_bert.modeling - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz from cache at /root/.pytorch_pretrained_bert/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c\n",
            "2022-06-26 19:31:42,657 - INFO - pytorch_pretrained_bert.modeling - extracting archive file /root/.pytorch_pretrained_bert/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c to temp dir /tmp/tmp0df1qtwf\n",
            "2022-06-26 19:31:46,295 - INFO - pytorch_pretrained_bert.modeling - Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "2022-06-26 19:31:48,093 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 300, 'input_size': 768, 'num_layers': 2, 'type': 'gru'} and extras {'vocab': Vocabulary with namespaces:  labels, Size: 54 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
            "2022-06-26 19:31:48,093 - INFO - allennlp.common.params - model.doc_encoder.type = gru\n",
            "2022-06-26 19:31:48,093 - INFO - allennlp.common.params - model.doc_encoder.batch_first = True\n",
            "2022-06-26 19:31:48,093 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2022-06-26 19:31:48,093 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2022-06-26 19:31:48,094 - INFO - allennlp.common.params - model.doc_encoder.bidirectional = True\n",
            "2022-06-26 19:31:48,094 - INFO - allennlp.common.params - model.doc_encoder.dropout = 0.5\n",
            "2022-06-26 19:31:48,094 - INFO - allennlp.common.params - model.doc_encoder.hidden_size = 300\n",
            "2022-06-26 19:31:48,094 - INFO - allennlp.common.params - model.doc_encoder.input_size = 768\n",
            "2022-06-26 19:31:48,094 - INFO - allennlp.common.params - model.doc_encoder.num_layers = 2\n",
            "2022-06-26 19:31:48,094 - INFO - allennlp.common.params - model.doc_encoder.batch_first = True\n",
            "2022-06-26 19:31:48,121 - INFO - allennlp.common.params - model.const_path = data\n",
            "2022-06-26 19:31:48,121 - INFO - allennlp.common.params - model.tokens_namespace = tokens\n",
            "2022-06-26 19:31:48,121 - INFO - allennlp.common.params - model.use_sim = True\n",
            "2022-06-26 19:31:48,121 - INFO - allennlp.common.params - model.use_classifier = False\n",
            "2022-06-26 19:31:49,166 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
            "{'unmatched': 0, 'amendmentxiv': 1, 'first_amendment': 2, 'fourth_amendment': 3, 'fifth_amendment': 4, 'articlei#section8': 5, 'eighth_amendment': 6, 'sixth_amendment': 7, 'seventh_amendment': 8, 'amendmentxi': 9, 'articleiv#section2': 10, 'amendmentxv': 11, 'second_amendment': 12, 'tenth_amendment': 13, 'articleiv#section1': 14, 'articleii#section2': 15, 'amendmentxiii': 16, 'amendmentxxi': 17, 'articlei#section10': 18, 'signers': 19, 'amendmentxvii': 20, 'articleii#section1': 21, 'amendmentxvi': 22, 'articlei#section3': 23, 'amendmentxviii': 24, 'amendmentxix': 25, 'amendmentxxv': 26, 'amendmentxx': 27, 'ninth_amendment': 28, 'articlei#section9': 29, 'articlei#section2': 30, 'articlei#section7': 31, 'amendmentxxiv': 32, 'amendmentxii': 33, 'amendmentxxvi': 34, 'amendmentxxii': 35, 'articlei#section6': 36, 'articlevi': 37, 'articleiii#section3': 38, 'articleiii#section2': 39, 'articlei#section5': 40, 'articleiv#section3': 41, 'third_amendment': 42, 'articleiii#section1': 43, 'amendmentxxiii': 44, 'articlei#section4': 45, 'articlevii': 46, 'preamble': 47, 'articleii#section4': 48, 'articleiv#section4': 49, 'amendmentxxvii': 50, 'articlei#section1': 51, 'articlev': 52, 'articleii#section3': 53}\n",
            "dict_keys(['articleii#section2', 'amendmentxxi', 'second_amendment', 'articleiv#section4', 'articlei#section1', 'articleii#section3', 'articlev', 'third_amendment', 'articleiii#section2', 'articlei#section4', 'amendmentxiv', 'articleii#section4', 'preamble', 'amendmentxi', 'signers', 'tenth_amendment', 'articlei#section2', 'articleiv#section1', 'amendmentxxiii', 'articlei#section5', 'amendmentxvi', 'articleii#section1', 'sixth_amendment', 'amendmentxx', 'amendmentxii', 'articlei#section7', 'amendmentxviii', 'articleiii#section3', 'articleiv#section2', 'articlei#section8', 'articleiii#section1', 'eighth_amendment', 'amendmentxvii', 'fifth_amendment', 'articleiv#section3', 'amendmentxxvii', 'amendmentxxii', 'articlevi', 'amendmentxxvi', 'amendmentxxiv', 'amendmentxxv', 'amendmentxix', 'articlei#section10', 'amendmentxiii', 'ninth_amendment', 'articlei#section3', 'first_amendment', 'articlevii', 'articlei#section9', 'articlei#section6', 'fourth_amendment', 'seventh_amendment', 'amendmentxv'])\n",
            "Embedding the constitution... this could take a minute...\n",
            "Done embedding the constitution.\n",
            "2022-06-26 19:32:41,258 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'token_indexers': {'tokens': {'do_lowercase': False, 'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained', 'use_starting_offsets': True}}, 'type': 'legal_reader'} and extras {}\n",
            "2022-06-26 19:32:41,259 - INFO - allennlp.common.params - dataset_reader.type = legal_reader\n",
            "2022-06-26 19:32:41,259 - INFO - allennlp.common.from_params - instantiating class <class 'mylib.legal_reader.LegalDatasetReader'> from params {'token_indexers': {'tokens': {'do_lowercase': False, 'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained', 'use_starting_offsets': True}}} and extras {}\n",
            "2022-06-26 19:32:41,259 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'bert-base-cased', 'type': 'bert-pretrained', 'use_starting_offsets': True} and extras {}\n",
            "2022-06-26 19:32:41,259 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = bert-pretrained\n",
            "2022-06-26 19:32:41,259 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'bert-base-cased', 'use_starting_offsets': True} and extras {}\n",
            "2022-06-26 19:32:41,259 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.pretrained_model = bert-base-cased\n",
            "2022-06-26 19:32:41,259 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.use_starting_offsets = True\n",
            "2022-06-26 19:32:41,259 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.do_lowercase = False\n",
            "2022-06-26 19:32:41,259 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.never_lowercase = None\n",
            "2022-06-26 19:32:41,260 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_pieces = 512\n",
            "2022-06-26 19:32:42,022 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
            "2022-06-26 19:32:42,050 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "731it [00:00, 2809.37it/s]{'pos': 395, 'neg': 753}\n",
            "1148it [00:00, 3636.40it/s]\n",
            "2022-06-26 19:32:46,126 - WARNING - allennlp.data.token_indexers.wordpiece_indexer - Too many wordpieces, truncating: ['Had', 'the', 'doctor', 'defendant', 'here', ',', 'or', 'even', 'the', 'nondoctor', 'defendant', ',', 'been', 'convicted', 'for', 'doing', 'nothing', 'more', 'than', 'expressing', 'opinions', 'to', 'persons', 'coming', 'to', 'the', 'clinic', 'that', 'certain', 'contraceptive', 'devices', ',', 'medicines', 'or', 'practices', 'would', 'do', 'them', 'good', 'and', 'would', 'be', 'desirable', ',', 'or', 'for', 'telling', 'people', 'how', 'devices', 'could', 'be', 'used', ',', 'I', 'can', 'think', 'of', 'no', 'reasons', 'at', 'this', 'time', 'why', 'their', 'expressions', 'of', 'views', 'would', 'not', 'be', '[', 'p508', ']', 'protected', 'by', 'the', 'First', 'and', 'Fourteenth', 'Amendments', ',', 'which', 'guarantee', 'freedom', 'of', 'speech', '.', 'Cf', '.', 'Brotherhood', 'of', 'Railroad', 'Trainmen', 'v.', 'Virginia', 'ex', 'rel', '.', 'Virginia', 'State', 'Bar', ',', '377', 'U.S.', '1', ';', 'NAACP', 'v.', 'Button', ',', '371', 'U.S.', '415', '.', 'But', 'speech', 'is', 'one', 'thing', ';', 'conduct', 'and', 'physical', 'activities', 'are', 'quite', 'another', '.', 'See', ',', 'e.g.', ',', 'Cox', 'v.', 'Louisiana', ',', '379', 'U.S.', '536', ',', '554', '-', '555', ';', 'Cox', 'v.', 'Louisiana', ',', '379', 'U.S.', '559', ',', '563', '-', '564', ';', 'i', 'd', '.', '575', '-', '584', '(', 'concurring', 'opinion', ')', ';', 'Giboney', 'v.', 'Empire', 'Storage', '&', 'Ice', 'Co.', ',', '336', 'U.S.', '490', ';', 'cf', '.', 'Reynolds', 'v.', 'United', 'States', ',', '98', 'U.S.', '145', ',', '163', '-', '164', '.', 'The', 'two', 'defendants', 'here', 'were', 'active', 'participants', 'in', 'an', 'organization', 'which', 'gave', 'physical', 'examinations', 'to', 'women', ',', 'advised', 'them', 'what', 'kind', 'of', 'contraceptive', 'devices', 'or', 'medicines', 'would', 'most', 'likely', 'be', 'satisfactory', 'for', 'them', ',', 'and', 'then', 'supplied', 'the', 'devices', 'themselves', ',', 'all', 'for', 'a', 'graduated', 'scale', 'of', 'fees', ',', 'based', 'on', 'the', 'family', 'income', '.', 'Thus', ',', 'these', 'defendants', 'admittedly', 'engaged', 'with', 'others', 'in', 'a', 'planned', 'course', 'of', 'conduct', 'to', 'help', 'people', 'violate', 'the', 'Connecticut', 'law', '.', 'Merely', 'because', 'some', 'speech', 'was', 'used', 'in', 'carrying', 'on', 'that', 'conduct', '--', 'just', 'as', ',', 'in', 'ordinary', 'life', ',', 'some', 'speech', 'accompanies', 'most', 'kinds', 'of', 'conduct', '--', 'we', 'are', 'not', ',', 'in', 'my', 'view', ',', 'justified', 'in', 'holding', 'that', 'the', 'First', 'Amendment', 'forbids', 'the', 'State', 'to', 'punish', 'their', 'conduct', '.', 'Strongly', 'as', 'I', 'desire', 'to', 'protect', 'all', 'First', 'Amendment', 'freedoms', ',', 'I', 'am', 'unable', 'to', 'stretch', 'the', 'Amendment', 'so', 'as', 'to', 'afford', 'protection', 'to', 'the', 'conduct', 'of', 'these', 'defendants', 'in', 'violating', 'the', 'Connecticut', 'law', '.', 'What', 'would', 'be', 'the', 'constitutional', 'fate', 'of', 'the', 'law', 'if', 'hereafter', 'applied', 'to', 'punish', 'nothing', 'but', 'speech', 'is', ',', 'as', 'I', 'have', 'said', ',', 'quite', 'another', 'matter', '.', 'The', 'Court', 'talks', 'about', 'a', 'constitutional', '\"', 'right', 'of', 'privacy', '\"', 'as', 'though', 'there', 'is', 'some', 'constitutional', 'provision', 'or', 'provisions', 'forbidding', 'any', 'law', 'ever', 'to', 'be', 'passed', 'which', 'might', 'abridge', 'the', '\"', 'privacy', '\"', 'of', 'individuals', '.', 'But', 'there', 'is', 'not', '.', 'There', 'are', ',', 'of', 'course', ',', 'guarantees', 'in', 'certain', 'specific', 'constitutional', 'provisions', 'which', 'are', 'designed', 'in', 'part', 'to', 'protect', 'privacy', 'at', 'certain', 'times', 'and', 'places', 'with', 'respect', 'to', 'certain', 'activities', '.', 'Such', ',', 'for', 'example', ',', 'is', 'the', 'Fourth', '[', 'p509', ']', 'Amendment', \"'s\", 'guarantee', 'against', '\"', 'unreasonable', 'searches', 'and', 'seizures', '.', '\"', 'But', 'I', 'think', 'it', 'belittles', 'that', 'Amendment', 'to', 'talk', 'about', 'it', 'as', 'though', 'it', 'protects', 'nothing', 'but', '\"', 'privacy', '.', '\"', 'To', 'treat', 'it', 'that', 'way', 'is', 'to', 'give', 'it', 'a', 'niggardly', 'interpretation', ',', 'not', 'the', 'kind', 'of', 'liberal', 'reading', 'I', 'think', 'any', 'Bill', 'of', 'Rights', 'provision', 'should', 'be', 'given', '.', 'The', 'average', 'man', 'would', 'very', 'likely', 'not', 'have', 'his', 'feelings', 'soothed', 'any', 'more', 'by', 'having', 'his', 'property', 'seized', 'openly', 'than', 'by', 'having', 'it', 'seized', 'privately', 'and', 'by', 'stealth', '.', 'He', 'simply', 'wants', 'his', 'property', 'left', 'alone', '.', 'And', 'a', 'person', 'can', 'be', 'just', 'as', 'much', ',', 'if', 'not', 'more', ',', 'irritated', ',', 'annoyed', 'and', 'injured', 'by', 'an', 'unceremonious', 'public', 'arrest', 'by', 'a', 'policeman', 'as', 'he', 'is', 'by', 'a', 'seizure', 'in', 'the', 'privacy', 'of', 'his', 'office', 'or', 'home', '.']\n",
            "2022-06-26 19:32:46,311 - WARNING - allennlp.data.token_indexers.wordpiece_indexer - Too many wordpieces, truncating: ['The', 'due', 'process', 'argument', 'which', 'my', 'Brothers', 'HARLAN', 'and', 'WHITE', 'adopt', 'here', 'is', 'based', ',', 'as', 'their', 'opinions', 'indicate', ',', 'on', 'the', 'premise', 'that', 'this', 'Court', 'is', 'vested', 'with', 'power', 'to', 'invalidate', 'all', 'state', 'laws', 'that', 'it', 'considers', 'to', 'be', 'arbitrary', ',', 'capricious', ',', 'unreasonable', ',', 'or', 'oppressive', ',', 'or', 'on', 'this', 'Court', \"'s\", 'belief', 'that', 'a', 'particular', 'state', 'law', 'under', 'scrutiny', 'has', 'no', '\"', 'rational', 'or', 'justifying', '\"', 'purpose', ',', 'or', 'is', 'offensive', 'to', 'a', '\"', 'sense', 'of', 'fairness', 'and', 'justice', '.', '\"', '[', 'n3', ']', 'If', 'these', 'formulas', 'based', 'on', '\"', 'natural', 'justice', ',', '\"', 'or', 'others', 'which', 'mean', 'the', 'same', 'thing', ',', '[', 'n4', ']', 'are', 'to', 'prevail', ',', 'they', 'require', 'judges', 'to', 'determine', '[', 'p512', ']', 'what', 'is', 'or', 'is', 'not', 'constitutional', 'on', 'the', 'basis', 'of', 'their', 'own', 'appraisal', 'of', 'what', 'laws', 'are', 'unwise', 'or', 'unnecessary', '.', 'The', 'power', 'to', 'make', 'such', 'decisions', 'is', ',', 'of', 'course', ',', 'that', 'of', 'a', 'legislative', 'body', '.', 'Surely', 'it', 'has', 'to', 'be', 'admitted', 'that', 'no', 'provision', 'of', 'the', 'Constitution', 'specifically', 'gives', 'such', 'blanket', 'power', 'to', 'courts', 'to', 'exercise', 'such', 'a', 'supervisory', 'veto', 'over', 'the', 'wisdom', 'and', 'value', 'of', 'legislative', 'policies', 'and', 'to', 'hold', 'unconstitutional', 'those', 'laws', 'which', 'they', 'believe', 'unwise', 'or', 'dangerous', '.', 'I', 'readily', 'admit', 'that', 'no', 'legislative', 'body', ',', 'state', 'or', 'national', ',', 'should', 'pass', 'laws', 'that', 'can', 'justly', 'be', 'given', 'any', '[', 'p513', ']', 'of', 'the', 'invidious', 'labels', 'invoked', 'as', 'constitutional', 'excuses', 'to', 'strike', 'down', 'state', 'laws', '.', 'But', 'perhaps', 'it', 'is', 'not', 'too', 'much', 'to', 'say', 'that', 'no', 'legislative', 'body', 'ever', 'does', 'pass', 'laws', 'without', 'believing', 'that', 'they', 'will', 'accomplish', 'a', 'sane', ',', 'rational', ',', 'wise', 'and', 'justifiable', 'purpose', '.', 'While', 'I', 'completely', 'subscribe', 'to', 'the', 'holding', 'of', 'Marbury', 'v.', 'Madison', ',', '1', 'Cranch', '137', ',', 'and', 'subsequent', 'cases', ',', 'that', 'our', 'Court', 'has', 'constitutional', 'power', 'to', 'strike', 'down', 'statutes', ',', 'state', 'or', 'federal', ',', 'that', 'violate', 'commands', 'of', 'the', 'Federal', 'Constitution', ',', 'I', 'do', 'not', 'believe', 'that', 'we', 'are', 'granted', 'power', 'by', 'the', 'Due', 'Process', 'Clause', 'or', 'any', 'other', 'constitutional', 'provision', 'or', 'provisions', 'to', 'measure', 'constitutionality', 'by', 'our', 'belief', 'that', 'legislation', 'is', 'arbitrary', ',', 'capricious', 'or', 'unreasonable', ',', 'or', 'accomplishes', 'no', 'justifiable', 'purpose', ',', 'or', 'is', 'offensive', 'to', 'our', 'own', 'notions', 'of', '\"', 'civilized', 'standards', 'of', 'conduct', '.', '\"', '[', 'n5', ']', 'Such', 'an', 'appraisal', 'of', 'the', 'wisdom', 'of', 'legislation', 'is', 'an', 'attribute', 'of', 'the', 'power', 'to', 'make', 'laws', ',', 'not', 'of', 'the', 'power', 'to', 'interpret', 'them', '.', 'The', 'use', 'by', 'federal', 'courts', 'of', 'such', 'a', 'formula', 'or', 'doctrine', 'or', 'whatnot', 'to', 'veto', 'federal', 'or', 'state', 'laws', 'simply', 'takes', 'away', 'from', 'Congress', 'and', 'States', 'the', 'power', 'to', 'make', 'laws', 'based', 'on', 'their', 'own', 'judgment', 'of', 'fairness', 'and', 'wisdom', ',', 'and', 'transfers', 'that', 'power', 'to', 'this', 'Court', 'for', 'ultimate', 'determination', '--', 'a', 'power', 'which', 'was', 'specifically', 'denied', 'to', 'federal', 'courts', 'by', 'the', 'convention', 'that', 'framed', 'the', 'Constitution', '.', '[', 'n6', ']', '[', 'p514', ']']\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/run.py\", line 18, in <module>\n",
            "    main(prog=\"allennlp\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/__init__.py\", line 72, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/predict.py\", line 200, in _predict\n",
            "    manager.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/predict.py\", line 176, in run\n",
            "    for model_input_instance, result in zip(batch, self._predict_instances(batch)):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/commands/predict.py\", line 137, in _predict_instances\n",
            "    results = [self._predictor.predict_instance(batch_data[0])]\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1Lt5kF5Xs5S1KHOdKGEcZMAPVCDlEo93_/legal-linking-master/mylib/legal_predictor.py\", line 24, in predict_instance\n",
            "    result = super().predict_instance(instance)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/predictors/predictor.py\", line 58, in predict_instance\n",
            "    outputs = self._model.forward_on_instance(instance)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/models/model.py\", line 124, in forward_on_instance\n",
            "    return self.forward_on_instances([instance])[0]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/models/model.py\", line 155, in forward_on_instances\n",
            "    outputs = self.decode(self(**model_input))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1Lt5kF5Xs5S1KHOdKGEcZMAPVCDlEo93_/legal-linking-master/mylib/legal_model.py\", line 133, in forward\n",
            "    const_doc_emb = self._doc_encoder(self.const_emb, self.const_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py\", line 73, in forward\n",
            "    self.sort_and_run_forward(self._module, inputs, mask, hidden_state)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allennlp/modules/encoder_base.py\", line 92, in sort_and_run_forward\n",
            "    num_valid = torch.sum(mask[:, 0]).int().item()\n",
            "RuntimeError: CUDA error: an illegal memory access was encountered\n",
            "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
            "2022-06-26 19:32:46,466 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmp0a4ilwzj\n"
          ]
        }
      ],
      "source": [
        "!allennlp predict \"/content/drive/MyDrive/legal-linking-master/tmp1/model.tar.gz\" data/validation/all_validation --include-package mylib --cuda-device 0 --use-dataset-reader --output results/gru.txt --predictor legal_predictor --silent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONhH1BiRdpY9",
        "outputId": "ad928140-3007-4769-f16b-e8b6af399d32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "{'pos': 395, 'neg': 753}\n",
            "{'pos': 307, 'neg': 841}\n",
            "06/26/2022 19:37:36 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
            "100% 2296/2296 [00:00<00:00, 15960.27it/s]\n",
            "P: 0.8171091445425318\n",
            "R: 0.5539999999998892\n",
            "F1: 0.6603098926811236\n"
          ]
        }
      ],
      "source": [
        "!python score.py --gold data/validation/all_validation --pred results/gru.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8pS1s0qfLex"
      },
      "outputs": [],
      "source": [
        "!python ensemble.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ensemble.py"
      ],
      "metadata": {
        "id": "tawU3GOjUNBu",
        "outputId": "8f08e911-889a-489c-e51a-1606ddb5341f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#combination of all 3-MAJORITY VOTING\n",
            "with open(\"results/rules.txt\") as f1, open(\"results/gru.txt\") as f2, open(\"results/linear-remove.txt\") as f3, open(\"results/new_ensemble7.txt\",\"w\") as out:\n",
            "    line1 = f1.readline()\n",
            "    line2 = f2.readline()\n",
            "    line3 = f3.readline()\n",
            "    cnt = 1\n",
            "    while line1 and line2 and line3:\n",
            "        rules = list()\n",
            "        newrules = set()\n",
            "        text, rulelabel = line1.strip().split(\"\\t\")\n",
            "        text, bertlabel = line2.strip().split(\"\\t\")\n",
            "        text, linearlabel = line3.strip().split(\"\\t\")\n",
            "        rules.append(rulelabel)\n",
            "        rules.append(bertlabel)\n",
            "        rules.append(linearlabel)\n",
            "        for i in rules:\n",
            "          count=rules.count(i)\n",
            "          if count > 1:\n",
            "            newrules.add(i)\n",
            "        if len(newrules) == 0:\n",
            "          newrules.add(rulelabel)\n",
            "        \n",
            "        if len(text.strip()) > 0:\n",
            "            outstring = \"{}\\t{}\\n\".format(text, \",\".join(newrules))\n",
            "            out.write(outstring)\n",
            "        line1 = f1.readline()\n",
            "        line2 = f2.readline()\n",
            "        line3 = f3.readline()\n",
            "        cnt += 1\n",
            "\n",
            "#combination of rules-gru (if unmatched then go with linear)\n",
            "# with open(\"results/rules.txt\") as f1, open(\"results/linear.txt\") as f2, open(\"results/gru.txt\") as f3, open(\"results/rules-linear-gru.txt\",\"w\") as out:\n",
            "#     line1 = f1.readline()\n",
            "#     line2 = f2.readline()\n",
            "#     line3 = f3.readline()\n",
            "#     cnt = 1\n",
            "#     while line1 and line2 and line3:\n",
            "#         newrules = set()\n",
            "#         text, rulelabel = line1.strip().split(\"\\t\")\n",
            "#         text, bertlabel = line2.strip().split(\"\\t\")\n",
            "#         text, linearlabel = line3.strip().split(\"\\t\")\n",
            "#         newrules.add(rulelabel)\n",
            "#         newrules.add(bertlabel)\n",
            "#         if len(newrules) > 1 and \"unmatched\" in newrules:\n",
            "#             newrules.remove(\"unmatched\")\n",
            "#         if len(newrules) == 0:\n",
            "#             newrules.add(linearlabel)\n",
            "#         if len(text.strip()) > 0:\n",
            "#             outstring = \"{}\\t{}\\n\".format(text, \",\".join(newrules))\n",
            "#             out.write(outstring)\n",
            "#         line1 = f1.readline()\n",
            "#         line2 = f2.readline()\n",
            "#         line3 = f3.readline()\n",
            "#         cnt += 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python score.py --gold data/validation/all_validation.txt --pred results/new_ensemble7.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdMF6Iejxx7N",
        "outputId": "91e74f99-ec2d-4068-9551-ed5e76382c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 152, got 144\n",
            "  return f(*args, **kwds)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "{'pos': 395, 'neg': 753}\n",
            "{'pos': 263, 'neg': 885}\n",
            "08/06/2022 08:07:03 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
            "100% 2296/2296 [00:00<00:00, 14171.55it/s]\n",
            "P: 0.8165137614676402\n",
            "R: 0.5339999999998932\n",
            "F1: 0.6457073760100731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4j1q78UhyG8g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}